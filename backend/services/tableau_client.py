"""
Tableau Metadata API å®¢æˆ·ç«¯
ä» Tableau Server æŠ“å–å…ƒæ•°æ®
"""
import os
import sys
import json
import requests
from collections import defaultdict
from typing import Optional, List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from backend.config import Config

class TableauMetadataClient:
    """Tableau Metadata API å®¢æˆ·ç«¯"""
    
    def __init__(self, base_url: str, username: str = None, password: str = None, 
                 pat_name: str = None, pat_secret: str = None):
        self.base_url = base_url.rstrip('/')
        self.username = username
        self.password = password
        self.pat_name = pat_name
        self.pat_secret = pat_secret
        self.auth_token: Optional[str] = None
        self.site_id: Optional[str] = None
        self.api_version = "3.10"
    
    def sign_in(self) -> bool:
        """ç™»å½•è·å–è®¤è¯ token (æ”¯æŒç”¨æˆ·åå¯†ç æˆ– PAT)"""
        signin_url = f"{self.base_url}/api/{self.api_version}/auth/signin"
        
        # æ ¹æ®é…ç½®é€‰æ‹©è®¤è¯æ–¹å¼
        if self.pat_name and self.pat_secret:
            # PAT è®¤è¯
            payload = {
                "credentials": {
                    "personalAccessTokenName": self.pat_name,
                    "personalAccessTokenSecret": self.pat_secret,
                    "site": {"contentUrl": ""}
                }
            }
            print(f"  ä½¿ç”¨ PAT è®¤è¯: {self.pat_name}")
        else:
            # ç”¨æˆ·åå¯†ç è®¤è¯
            payload = {
                "credentials": {
                    "name": self.username,
                    "password": self.password,
                    "site": {"contentUrl": ""}
                }
            }
            print(f"  ä½¿ç”¨ç”¨æˆ·åå¯†ç è®¤è¯: {self.username}")
        
        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json"
        }
        
        try:
            response = requests.post(signin_url, headers=headers, json=payload, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                credentials = data.get("credentials", {})
                self.auth_token = credentials.get("token")
                self.site_id = credentials.get("site", {}).get("id")
                print(f"âœ… ç™»å½•æˆåŠŸ (Token: {self.auth_token[:20]}...)")
                return True
            else:
                print(f"âŒ ç™»å½•å¤±è´¥: {response.text}")
                return False
        except Exception as e:
            print(f"âŒ ç™»å½•å¼‚å¸¸: {e}")
            return False
    
    def sign_out(self):
        """ç™»å‡ºé‡Šæ”¾ token"""
        if not self.auth_token:
            return
        
        signout_url = f"{self.base_url}/api/{self.api_version}/auth/signout"
        headers = {"X-Tableau-Auth": self.auth_token}
        
        try:
            response = requests.post(signout_url, headers=headers, timeout=30)
            if response.status_code == 204:
                print("âœ… å·²ç™»å‡º")
        except Exception as e:
            print(f"ç™»å‡ºå¼‚å¸¸: {e}")
        finally:
            self.auth_token = None
    
    def execute_query(self, query: str) -> Dict[str, Any]:
        """æ‰§è¡Œ GraphQL æŸ¥è¯¢"""
        if not self.auth_token:
            raise RuntimeError("æœªç™»å½•ï¼Œè¯·å…ˆè°ƒç”¨ sign_in()")
        
        url = f"{self.base_url}/api/metadata/graphql"
        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json",
            "X-Tableau-Auth": self.auth_token
        }
        
        response = requests.post(url, headers=headers, json={"query": query}, timeout=60)
        
        if response.status_code == 200:
            return response.json()
        else:
            raise RuntimeError(f"GraphQL æŸ¥è¯¢å¤±è´¥: {response.status_code} - {response.text}")
    
    def fetch_views_usage(self) -> tuple:
        """ä» REST API è·å–è§†å›¾ä½¿ç”¨ç»Ÿè®¡ (REST API)
        
        è¿”å›:
            tuple: (usage_map, luid_map)
                - usage_map: Dict[str, int] - {view_luid: total_view_count}
                - luid_map: Dict[tuple, str] - {(workbook_id, view_name): view_luid}
                  ç”¨äºå›æº¯è¡¥å…… GraphQL åŒæ­¥æ—¶ç¼ºå¤±çš„ luid
        """
        if not self.auth_token or not self.site_id:
            raise RuntimeError("æœªç™»å½•ï¼Œè¯·å…ˆè°ƒç”¨ sign_in()")
        
        # REST API endpoint for views
        url = f"{self.base_url}/api/{self.api_version}/sites/{self.site_id}/views"
        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json",
            "X-Tableau-Auth": self.auth_token
        }
        
        usage_map = {}
        luid_map = {}  # æ–°å¢ï¼š(workbook_id, view_name) -> view_luid æ˜ å°„
        page_number = 1
        page_size = 100
        
        print(f"  æ­£åœ¨è°ƒç”¨ REST API è·å–è®¿é—®ç»Ÿè®¡: {url}")
        
        while True:
            params = {
                "pageNumber": page_number,
                "pageSize": page_size,
                "includeUsageStatistics": "true"
            }
            
            try:
                response = requests.get(url, headers=headers, params=params, timeout=30)
                
                if response.status_code != 200:
                    print(f"  âŒ REST API è·å–å¤±è´¥: {response.status_code} - {response.text}")
                    break
                
                data = response.json()
                views = data.get("views", {}).get("view", [])
                
                if not views:
                    break
                
                for view in views:
                    luid = view.get("id")
                    view_name = view.get("name")
                    workbook = view.get("workbook", {})
                    workbook_id = workbook.get("id") if workbook else None
                    
                    usage = view.get("usage", {})
                    # usage å¯èƒ½æ˜¯ Noneï¼Œä¹Ÿå¯èƒ½æ²¡æœ‰ totalViewCount
                    if usage:
                        total_count = usage.get("totalViewCount", 0)
                        if luid:
                            usage_map[luid] = int(total_count)
                    
                    # æ„å»º luid æ˜ å°„ç”¨äºå›æº¯è¡¥å……
                    if luid and workbook_id and view_name:
                        luid_map[(workbook_id, view_name)] = luid
                
                # Check pagination
                pagination = data.get("pagination", {})
                total_available = int(pagination.get("totalAvailable", 0))
                
                print(f"    - Page {page_number}: è·å– {len(views)} ä¸ªè§†å›¾, æ€»è¿›åº¦ {len(usage_map)}/{total_available}")
                
                if len(usage_map) >= total_available or len(views) < page_size:
                    break
                    
                page_number += 1
                
            except Exception as e:
                print(f"  âŒ è·å–è§†å›¾ç»Ÿè®¡å¼‚å¸¸: {e}")
                break
        
        print(f"  ğŸ“Œ æ„å»º luid æ˜ å°„: {len(luid_map)} æ¡ (ç”¨äºå›æº¯è¡¥å……)")
        return usage_map, luid_map    
    def fetch_databases(self) -> List[Dict]:
        """è·å–æ‰€æœ‰æ•°æ®åº“ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        query = """
        {
            databaseServers {
                id
                luid
                name
                connectionType
                hostName
                port
                service
                description
                isCertified
                certificationNote
            }
        }
        """
        result = self.execute_query(query)
        # å…¼å®¹å¤„ç†ï¼šå…ˆå°è¯• databaseServersï¼Œå¤±è´¥åˆ™å›é€€åˆ° databases
        data = result.get("data", {})
        servers = data.get("databaseServers")
        if servers is not None:
            return servers
        # å›é€€åˆ°æ—§æŸ¥è¯¢
        return self._fetch_databases_fallback()
    
    def _fetch_databases_fallback(self) -> List[Dict]:
        """å›é€€ï¼šä½¿ç”¨æ—§ç‰ˆæŸ¥è¯¢è·å–æ•°æ®åº“"""
        query = """
        {
            databases {
                id
                name
                connectionType
            }
        }
        """
        result = self.execute_query(query)
        return result.get("data", {}).get("databases", [])
    
    def fetch_tables(self) -> List[Dict]:
        """è·å–æ‰€æœ‰æ•°æ®è¡¨ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        query = """
        {
            databaseTables {
                id
                luid
                name
                schema
                fullName
                description
                isEmbedded
                projectName
                database {
                    id
                    name
                    connectionType
                }
                columns {
                    id
                    name
                    description
                    remoteType
                    isNullable
                }
            }
        }
        """
        result = self.execute_query(query)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ï¼ˆæŸäº›å­—æ®µå¯èƒ½ä¸è¢«æ”¯æŒï¼‰
        if "errors" in result:
            print(f"  âš ï¸ GraphQL è­¦å‘Š: {result['errors']}")
            # å°è¯•ç®€åŒ–æŸ¥è¯¢
            return self._fetch_tables_fallback()
        
        return result.get("data", {}).get("databaseTables", [])
    
    def _fetch_tables_fallback(self) -> List[Dict]:
        """å›é€€ï¼šä½¿ç”¨ç®€åŒ–æŸ¥è¯¢è·å–è¡¨ï¼ˆåŒ…å«åˆ—ä¿¡æ¯ï¼‰"""
        query = """
        {
            databaseTables {
                id
                name
                schema
                fullName
                isEmbedded
                database {
                    id
                    name
                    connectionType
                }
                columns {
                    id
                    name
                    remoteType
                    description
                    isNullable
                }
            }
        }
        """
        result = self.execute_query(query)
        return result.get("data", {}).get("databaseTables", [])
    
    def fetch_datasource_by_id(self, ds_id: str) -> Optional[Dict]:
        """è·å–å•ä¸ªæ•°æ®æºè¯¦æƒ…"""
        query = """
        {
            publishedDatasources(filter: {id: "%s"}) {
                id
                name
                description
                projectName
                projectVizportalUrlId
                uri
                hasExtracts
                isCertified
                certificationNote
                certifierDisplayName
                owner {
                    id
                    username
                }
            }
        }
        """ % ds_id
        
        result = self.execute_query(query)
        if "errors" in result:
             print(f"  âš ï¸ è·å–å•æ•°æ®æºå¤±è´¥: {result['errors']}")
             return None
             
        data = result.get("data", {})
        ds_list = data.get("publishedDatasources") or []
        if ds_list:
            return ds_list[0]
        return None

    def fetch_datasources(self) -> List[Dict]:
        """è·å–æ‰€æœ‰å·²å‘å¸ƒæ•°æ®æºï¼ˆå¢å¼ºç‰ˆï¼‰"""
        query = """
        {
            publishedDatasources {
                id
                luid
                name
                description
                uri
                projectName
                hasExtracts
                extractLastRefreshTime
                extractLastIncrementalUpdateTime
                extractLastUpdateTime
                isCertified
                certificationNote
                certifierDisplayName
                containsUnsupportedCustomSql
                hasActiveWarning
                createdAt
                updatedAt
                vizportalUrlId
                owner {
                    id
                    username
                    name
                }
                upstreamTables {
                    id
                    name
                }
            }
        }
        """
        result = self.execute_query(query)
        
        # æ£€æŸ¥é”™è¯¯å¹¶å›é€€
        if "errors" in result:
            print(f"  âš ï¸ GraphQL è­¦å‘Š: {result['errors']}")
            return self._fetch_datasources_fallback()
        
        return result.get("data", {}).get("publishedDatasources", [])
    
    def _fetch_datasources_fallback(self) -> List[Dict]:
        """å›é€€ï¼šä½¿ç”¨ç®€åŒ–æŸ¥è¯¢è·å–æ•°æ®æº"""
        query = """
        {
            publishedDatasources {
                id
                name
                projectName
                hasExtracts
                extractLastRefreshTime
                isCertified
                owner {
                    username
                }
                upstreamTables {
                    id
                    name
                }
            }
        }
        """
        result = self.execute_query(query)
        return result.get("data", {}).get("publishedDatasources", [])
    
    def fetch_workbooks(self) -> List[Dict]:
        """è·å–æ‰€æœ‰å·¥ä½œç°¿ï¼ˆä¼˜åŒ–ç‰ˆï¼šRobust Aliased Chunking + Null Owner Fallbackï¼‰"""
        all_workbooks = []
        
        print(f"  æ­£åœ¨è·å–å·¥ä½œç°¿åˆ—è¡¨...")
        # 1. è·å–æ‰€æœ‰ ID (Safe Query)
        list_query = """
        {
            workbooks {
                id
                name
            }
        }
        """
        list_result = self.execute_query(list_query)
        if "errors" in list_result and not list_result.get("data"):
            print(f"  âš ï¸ è·å–å·¥ä½œç°¿åˆ—è¡¨å¤±è´¥: {list_result['errors']}")
            return []
            
        workbooks_meta = list_result.get("data", {}).get("workbooks") or []
        print(f"  éœ€åŒæ­¥ {len(workbooks_meta)} ä¸ªå·¥ä½œç°¿è¯¦æƒ…...")
        
        # 2. åˆ†æ‰¹è·å–è¯¦æƒ…
        chunk_size = 10
        total = len(workbooks_meta)
        
        for i in range(0, total, chunk_size):
            chunk = workbooks_meta[i:i+chunk_size]
            
            # å°è¯•æ‰¹é‡è·å– (å« metadata)
            try:
                self._fetch_workbooks_chunk(chunk, all_workbooks, include_owner=True)
            except Exception as e:
                print(f"  âš ï¸ æ‰¹æ¬¡ {i//chunk_size + 1} é‡åˆ°é”™è¯¯ï¼Œå°è¯•é™çº§é‡è¯• (ä¸å« Owner)...")
                try:
                    self._fetch_workbooks_chunk(chunk, all_workbooks, include_owner=False)
                except Exception as e2:
                    print(f"  âŒ æ‰¹æ¬¡ {i//chunk_size + 1} å½»åº•å¤±è´¥: {e2}")

            print(f"    - å·¥ä½œç°¿: å·²å¤„ç† {min(i+chunk_size, total)}/{total}")

        return all_workbooks
    
    def _fetch_workbooks_chunk(self, chunk: List[Dict], all_workbooks: List[Dict], include_owner: bool = True):
        """è¾…åŠ©ï¼šæ‰¹é‡è·å–å·¥ä½œç°¿è¯¦æƒ…"""
        query_parts = []
        owner_field = """
                    owner {
                        id
                        username
                        name
                    }
        """ if include_owner else ""
        
        for idx, wb in enumerate(chunk):
            wb_id = wb["id"]
            query_parts.append(f"""
            wb{idx}: workbooks(filter: {{id: "{wb_id}"}}) {{
                id
                luid
                name
                description
                uri
                projectName
                createdAt
                updatedAt
                containsUnsupportedCustomSql
                vizportalUrlId
                {owner_field}
                upstreamDatasources {{
                    id
                    name
                }}
                sheets {{
                    id
                    luid
                    name
                    path
                    index
                    createdAt
                    updatedAt
                }}
                dashboards {{
                    id
                    luid
                    name
                    path
                    index
                    createdAt
                    updatedAt
                    sheets {{
                        id
                    }}
                }}
                embeddedDatasources {{
                    id
                    name
                    upstreamDatasources {{
                        id
                        name
                    }}
                    upstreamTables {{
                        id
                        name
                    }}
                    fields {{
                        id
                        name
                        description
                        ... on ColumnField {{
                            dataType
                            role
                            isHidden
                            folderName
                        }}
                        ... on CalculatedField {{
                            dataType
                            role
                            isHidden
                            folderName
                            formula
                        }}
                    }}
                }}
            }}
            """)
        
        full_query = "{" + "\n".join(query_parts) + "}"
        result = self.execute_query(full_query)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ strict error (å¯¼è‡´ data ä¸º null)
        if "data" not in result or not result["data"]:
             # æŠ›å‡ºå¼‚å¸¸ä»¥è§¦å‘é™çº§
             raise Exception("Data is null, likely non-nullable field violation")
             
        data = result.get("data", {})
        
        for key, wb_list in data.items():
            if not wb_list: continue 
            wb_detail = wb_list[0]
            
            all_workbooks.append(wb_detail)
    
    def fetch_fields(self) -> List[Dict]:
        all_fields = []
        
        # 1. è·å–æ‰€æœ‰æ•°æ®æº ID
        print(f"  æ­£åœ¨è·å–æ•°æ®æºåˆ—è¡¨ä»¥åŒæ­¥å­—æ®µ...")
        ds_query = """
        {
            publishedDatasources {
                id
                name
            }
            embeddedDatasources {
                id
                name
                upstreamDatasources {
                    id
                    name
                }
                workbook {
                    id
                }
            }
        }
        """
        ds_result = self.execute_query(ds_query)
        if "errors" in ds_result and not ds_result.get("data"):
            print(f"  âš ï¸ è·å–æ•°æ®æºå¤±è´¥: {ds_result['errors']}")
            return []
            
        published = ds_result.get("data", {}).get("publishedDatasources") or []
        embedded = ds_result.get("data", {}).get("embeddedDatasources") or []
        
        # å»ºç«‹åµŒå…¥å¼åˆ°å‘å¸ƒæ˜ å°„
        embedded_to_published = {}
        for ds in embedded:
            upstreams = ds.get("upstreamDatasources") or []
            if upstreams:
                embedded_to_published[ds["id"]] = upstreams[0]["id"]
            
            # å»ºç«‹åµŒå…¥å¼æ•°æ®æºåˆ°å·¥ä½œç°¿çš„æ˜ å°„
            if ds.get("workbook"):
                f_wb_id = ds["workbook"]["id"]
                # æˆ‘ä»¬å°†åœ¨ _batch_fetch_fields ä¸­ç”¨åˆ°è¿™ä¸ªä¿¡æ¯ï¼Œä½†é‚£é‡Œæ˜¯é‡æ–°æŸ¥çš„
                # å®é™…ä¸Š _batch_fetch_fields ä¹Ÿéœ€è¦æ›´æ–°æŸ¥è¯¢æ¥è·å– workbook


        # åˆ†åˆ«å¤„ç†ä¸¤ç§æ•°æ®æº
        self._batch_fetch_fields(published, "publishedDatasources", all_fields)
        self._batch_fetch_fields(embedded, "embeddedDatasources", all_fields, embedded_to_published)
        
        print(f"  âœ… å…±é‡‡é›†åˆ° {len(all_fields)} ä¸ªå­—æ®µ")
        return all_fields

    def _batch_fetch_fields(self, datasources: List[Dict], type_name: str, all_fields: List[Dict], 
                             embedded_to_published: Dict = None):
        """æ‰¹é‡è·å–å­—æ®µè¯¦æƒ… (è¾…åŠ©æ–¹æ³•)"""
        if not datasources:
            return
        
        embedded_to_published = embedded_to_published or {}
        
        # ä¿®æ­£ï¼šä»…ç”±äºåµŒå…¥å¼æ•°æ®æºæœ¬èº«æœ‰ workbook å­—æ®µï¼Œå‘å¸ƒå¼æ•°æ®æºæ²¡æœ‰
        # æˆ‘ä»¬éœ€è¦åœ¨æŸ¥è¯¢ä¸­åŠ¨æ€å†³å®šæ˜¯å¦åŒ…å« workbook
        nested_workbook_query = ""
        if type_name == "embeddedDatasources":
            nested_workbook_query = """
                workbook {
                    id
                }"""

        print(f"  åŒæ­¥ {type_name}: {len(datasources)} ä¸ª...")
        chunk_size = 10
        total = len(datasources)
        
        for i in range(0, total, chunk_size):
            chunk = datasources[i:i+chunk_size]
            
            # åŠ¨æ€æ„å»º Alias Filter æŸ¥è¯¢
            query_parts = []
            for idx, ds in enumerate(chunk):
                ds_id = ds["id"]
                query_parts.append(f"""
                q{idx}: {type_name}(filter: {{id: "{ds_id}"}}) {{
                    id
                    name
                    {nested_workbook_query}
                    fields {{
                        __typename
                        id
                        name
                        description
                        ... on ColumnField {{
                            role
                            isHidden
                            upstreamColumns {{
                                id
                                name
                                remoteType
                                table {{
                                    id
                                    name
                                    __typename

                                    ... on CustomSQLTable {{
                                        upstreamTables {{
                                            id
                                            name
                                        }}
                                    }}
                                }}
                            }}
                        }}
                        ... on CalculatedField {{
                            role
                            isHidden
                            formula
                            upstreamFields {{
                                id
                                name
                                datasource {{
                                    id
                                    name
                                }}
                                ... on ColumnField {{
                                    upstreamColumns {{
                                        id
                                        name
                                        table {{
                                            id
                                            name
                                            __typename

                                            ... on CustomSQLTable {{
                                                upstreamTables {{
                                                    id
                                                    name
                                                }}
                                            }}
                                        }}
                                    }}
                                }}
                            }}
                        }}
                        ... on GroupField {{
                            role
                            isHidden
                        }}
                        ... on DatasourceField {{
                            remoteField {{
                                id
                                name
                                description
                                datasource {{
                                    id
                                    name
                                    __typename
                                }}
                            }}
                            upstreamColumns {{
                                id
                                name
                                table {{
                                    id
                                    name
                                    __typename

                                    ... on CustomSQLTable {{
                                        upstreamTables {{
                                            id
                                            name
                                        }}
                                    }}
                                }}
                            }}
                        }}
                    }}
                }}
                """)
            
            full_query = "{" + "\n".join(query_parts) + "}"
            
            try:
                result = self.execute_query(full_query)
                if "errors" in result:
                    print(f"  âš ï¸ æ‰¹æ¬¡ {i//chunk_size + 1} éƒ¨åˆ†å¤±è´¥: {result['errors'][0].get('message')}")
                
                data = result.get("data", {})
                if not data: continue
                
                for key, ds_list in data.items():
                    if not ds_list: continue
                    # filteræŸ¥è¯¢è¿”å›çš„æ˜¯åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ª
                    ds_data = ds_list[0]
                    ds_id = ds_data.get("id")
                    ds_name = ds_data.get("name")
                    
                    # è¡€ç¼˜ç©¿é€ï¼šå¦‚æœæ˜¯åµŒå…¥å¼ä¸”æœ‰ä¸Šæ¸¸å‘å¸ƒå¼ï¼Œåˆ™ä½¿ç”¨å‘å¸ƒå¼çš„ ID
                    final_ds_id = embedded_to_published.get(ds_id, ds_id)
                    
                    fields_list = ds_data.get("fields") or []
                    for field in fields_list:
                        if field and field.get("id"):
                            field["datasource_id"] = final_ds_id
                            field["datasource_name"] = ds_name
                            field["parent_datasource_id"] = ds_id  # ä¿ç•™åŸå§‹ ID å¤‡ç”¨
                            field["is_from_embedded_ds"] = (type_name == "embeddedDatasources")  # æ ‡è®°æ¥æº
                            
                            # æå– workbook ä¿¡æ¯ (ä»…é’ˆå¯¹ embeddedDatasources)
                            if ds_data.get("workbook"):
                                field["workbook"] = ds_data["workbook"]
                                
                            all_fields.append(field)
                
                print(f"    - {type_name}: å·²å¤„ç† {min(i+chunk_size, total)}/{total}")
                
            except Exception as e:
                print(f"  âŒ æ‰¹æ¬¡æŸ¥è¯¢å¼‚å¸¸: {e}")

    def fetch_calculated_fields(self) -> List[Dict]:
        """è·å–æ‰€æœ‰è®¡ç®—å­—æ®µ"""
        query = """
        {
            calculatedFields {
                id
                name
                description
                formula
                dataType
                role
                datasource {
                    id
                    name
                }
            }
        }
        """
        result = self.execute_query(query)
        
        # æ£€æŸ¥é”™è¯¯
        if "errors" in result:
            print(f"  âš ï¸ GraphQL é”™è¯¯: {result['errors']}")
            return []
        
        data = result.get("data")
        if data is None:
            return []
        
        calc_fields = data.get("calculatedFields") or []
        
        # å°è¯•ç©¿é€ï¼šå¯¹äºæ²¡æœ‰ datasource æˆ–è€… datasource ä¸ºåµŒå…¥å¼çš„ï¼Œ
        # åœ¨è¿”å›å‰å¯ä»¥æ ¹æ®å†…éƒ¨é€»è¾‘å¢å¼ºï¼Œä½†æœ€æ ¸å¿ƒçš„ç©¿é€å·²åœ¨ _batch_fetch_fields å®Œæˆã€‚
        # è¿™é‡Œæˆ‘ä»¬ç¡®ä¿ cf ä¹Ÿæºå¸¦å¿…è¦çš„ datasource_idã€‚
        for cf in calc_fields:
            if cf and cf.get("datasource"):
                cf["datasource_id"] = cf["datasource"].get("id")
            
        return calc_fields
    
    def fetch_views_with_fields(self) -> List[Dict]:
        """è·å–è§†å›¾åŠå…¶ä½¿ç”¨çš„å­—æ®µï¼ˆè¿­ä»£ä¼˜åŒ–ç‰ˆï¼šé€šè¿‡ Filter-ID åˆ†é¡µé‡‡é›†ï¼‰"""
        all_view_fields = []
        
        print(f"  æ­£åœ¨è·å–è§†å›¾å­—æ®µå…³è”(ä¼˜åŒ–ç‰ˆ)...")
        
        # 1. è·å–æ‰€æœ‰å·¥ä½œç°¿ ID
        wb_query = """
        {
            workbooks {
                id
                name
            }
        }
        """
        wb_result = self.execute_query(wb_query)
        if "errors" in wb_result and not wb_result.get("data"):
             print(f"  âš ï¸ è·å–å·¥ä½œç°¿åˆ—è¡¨å¤±è´¥: {wb_result['errors']}")
             return []
             
        workbooks = wb_result.get("data", {}).get("workbooks") or []
        print(f"  éœ€åŒæ­¥ {len(workbooks)} ä¸ªå·¥ä½œç°¿çš„è§†å›¾å…³è”...")
        
        # 2. é€ä¸ªå·¥ä½œç°¿æŸ¥è¯¢ (æˆ–å°æ‰¹é‡)
        # è€ƒè™‘åˆ°è§†å›¾åŒ…å«çš„å­—æ®µå¼•ç”¨èŠ‚ç‚¹å¯èƒ½å¾ˆå¤šï¼Œè¿™é‡Œé‡‡ç”¨æ¯æ¬¡æŸ¥ 5 ä¸ªå·¥ä½œç°¿
        chunk_size = 5
        total = len(workbooks)
        
        for i in range(0, total, chunk_size):
            chunk = workbooks[i:i+chunk_size]
            
            # åŠ¨æ€æ„å»º Alias Filter æŸ¥è¯¢ï¼ˆå¢åŠ ä»ªè¡¨æ¿å­—æ®µæŸ¥è¯¢ï¼‰
            query_parts = []
            for idx, wb in enumerate(chunk):
                wb_id = wb["id"]
                query_parts.append(f"""
                wb{idx}: workbooks(filter: {{id: "{wb_id}"}}) {{
                    id
                    name
                    sheets {{
                        id
                        name
                        sheetFieldInstances {{
                            id
                            name
                            datasource {{
                                id
                            }}
                        }}
                    }}
                    dashboards {{
                        id
                        name
                        upstreamSheetFieldInstances {{
                            id
                            name
                            datasource {{
                                id
                            }}
                        }}
                    }}
                }}
                """)
            
            full_query = "{" + "\n".join(query_parts) + "}"
            
            try:
                result = self.execute_query(full_query)
                if "errors" in result:
                    print(f"  âš ï¸ æ‰¹æ¬¡ {i//chunk_size + 1} éƒ¨åˆ†å¤±è´¥: {result['errors'][0].get('message')}")
                
                data = result.get("data", {})
                if not data: continue
                
                # è§£æåˆ«åç»“æœ
                for key, wb_list in data.items():
                    if not wb_list: continue
                    # workbooks è¿”å›çš„æ˜¯åˆ—è¡¨
                    wb_data = wb_list[0]
                    wb_id = wb_data.get("id")

                    # å¤„ç† sheets çš„å­—æ®µ
                    sheets = wb_data.get("sheets") or []
                    for sheet in sheets:
                        if not sheet: continue
                        view_id = sheet.get("id")
                        view_name = sheet.get("name")
                        fields = sheet.get("sheetFieldInstances") or []

                        for field in fields:
                            if field and field.get("id"):
                                all_view_fields.append({
                                    "view_id": view_id,
                                    "view_name": view_name,
                                    "view_type": "sheet",
                                    "workbook_id": wb_id,
                                    "field_id": field.get("id"),
                                    "field_name": field.get("name"),
                                    "datasource_id": (field.get("datasource") or {}).get("id")
                                })

                    # å¤„ç† dashboards çš„å­—æ®µ
                    dashboards = wb_data.get("dashboards") or []
                    for dashboard in dashboards:
                        if not dashboard: continue
                        view_id = dashboard.get("id")
                        view_name = dashboard.get("name")
                        fields = dashboard.get("upstreamSheetFieldInstances") or []

                        for field in fields:
                            if field and field.get("id"):
                                all_view_fields.append({
                                    "view_id": view_id,
                                    "view_name": view_name,
                                    "view_type": "dashboard",
                                    "workbook_id": wb_id,
                                    "field_id": field.get("id"),
                                    "field_name": field.get("name"),
                                    "datasource_id": (field.get("datasource") or {}).get("id")
                                })
                                
                print(f"    - å·²å¤„ç† {min(i+chunk_size, total)}/{total} ä¸ªå·¥ä½œç°¿, ç´¯è®¡å…³è” {len(all_view_fields)}")
                
            except Exception as e:
                print(f"  âŒ æ‰¹æ¬¡æŸ¥è¯¢å¼‚å¸¸: {e}")
        
        print(f"  âœ… æŠ“å–åˆ° {len(all_view_fields)} ä¸ªå­—æ®µå…³è”å…³ç³»")
        return all_view_fields
    
    def _fetch_views_with_fields_fallback(self) -> List[Dict]:
        """å¤‡ç”¨æ–¹æ³•ï¼šé€šè¿‡å·¥ä½œç°¿çš„æ•°æ®æºå…³ç³»é—´æ¥è·å–"""
        # ç”±äº Tableau API é™åˆ¶ï¼Œæˆ‘ä»¬é‡‡ç”¨ç®€åŒ–ç­–ç•¥ï¼š
        # é€šè¿‡ calculatedFields çš„ datasource å…³ç³»æ¥å»ºç«‹å­—æ®µâ†’è§†å›¾çš„é—´æ¥å…³è”
        query = """
        {
            workbooks {
                id
                name
                sheets {
                    id
                    name
                }
                upstreamDatasources {
                    id
                    name
                }
            }
        }
        """
        result = self.execute_query(query)
        
        if "errors" in result:
            print(f"  âš ï¸ å¤‡ç”¨æŸ¥è¯¢ä¹Ÿå¤±è´¥: {result['errors']}")
            return []
        
        data = result.get("data")
        if data is None:
            return []
        
        workbooks = data.get("workbooks") or []
        
        # è·å–æ•°æ®æºåˆ°å­—æ®µçš„æ˜ å°„
        ds_to_fields = {}
        fields_result = self.execute_query("""
        {
            publishedDatasources {
                id
                fields {
                    id
                    name
                }
            }
        }
        """)
        if "data" in fields_result and fields_result["data"]:
            for ds in (fields_result["data"].get("publishedDatasources") or []):
                if ds:
                    ds_to_fields[ds["id"]] = ds.get("fields") or []
        
        # æ„å»ºè§†å›¾â†’å­—æ®µå…³è”
        view_fields = []
        for wb in workbooks:
            if not wb:
                continue
            sheets = wb.get("sheets") or []
            datasources = wb.get("upstreamDatasources") or []
            
            for sheet in sheets:
                if not sheet:
                    continue
                # å°†æ•°æ®æºçš„å­—æ®µå…³è”åˆ°è§†å›¾
                for ds in datasources:
                    if not ds:
                        continue
                    for field in ds_to_fields.get(ds.get("id"), []):
                        if field and field.get("id"):
                            view_fields.append({
                                "view_id": sheet.get("id"),
                                "view_name": sheet.get("name"),
                                "workbook_id": wb.get("id"),
                                "field_id": field.get("id"),
                                "field_name": field.get("name")
                            })
        
        return view_fields


    def fetch_users(self) -> List[Dict]:
        """è·å–æ‰€æœ‰ Tableau ç”¨æˆ·"""
        query = """
        {
            tableauUsers {
                id
                luid
                name
                username
                email
                domain
                siteRole
            }
        }
        """
        result = self.execute_query(query)
        
        # æ£€æŸ¥é”™è¯¯
        if "errors" in result:
            print(f"  âš ï¸ GraphQL è­¦å‘Š (users): {result['errors']}")
            # å°è¯•ç®€åŒ–æŸ¥è¯¢
            return self._fetch_users_fallback()
        
        return result.get("data", {}).get("tableauUsers", [])
    
    def _fetch_users_fallback(self) -> List[Dict]:
        """å›é€€ï¼šé€šè¿‡ owner å…³ç³»æ”¶é›†ç”¨æˆ·"""
        users_dict = {}
        
        # ä»æ•°æ®æºæ”¶é›†ç”¨æˆ·
        ds_query = """
        {
            publishedDatasources {
                owner {
                    id
                    username
                    name
                }
            }
        }
        """
        ds_result = self.execute_query(ds_query)
        if "data" in ds_result and ds_result["data"]:
            for ds in (ds_result["data"].get("publishedDatasources") or []):
                if ds and ds.get("owner"):
                    owner = ds["owner"]
                    if owner.get("id"):
                        users_dict[owner["id"]] = {
                            "id": owner.get("id"),
                            "name": owner.get("name"),
                            "username": owner.get("username")
                        }
        
        # ä»å·¥ä½œç°¿æ”¶é›†ç”¨æˆ·
        wb_query = """
        {
            workbooks {
                owner {
                    id
                    username
                    name
                }
            }
        }
        """
        wb_result = self.execute_query(wb_query)
        if "data" in wb_result and wb_result["data"]:
            for wb in (wb_result["data"].get("workbooks") or []):
                if wb and wb.get("owner"):
                    owner = wb["owner"]
                    if owner.get("id"):
                        users_dict[owner["id"]] = {
                            "id": owner.get("id"),
                            "name": owner.get("name"),
                            "username": owner.get("username")
                        }
        
        return list(users_dict.values())
    
    def fetch_projects(self) -> List[Dict]:
        """è·å–æ‰€æœ‰ Tableau é¡¹ç›®"""
        # é€šè¿‡æ•°æ®æºå’Œå·¥ä½œç°¿çš„ projectName æ”¶é›†é¡¹ç›®ä¿¡æ¯
        # æ³¨æ„ï¼šTableau Metadata API æ²¡æœ‰ç›´æ¥çš„ projects æŸ¥è¯¢ï¼Œéœ€è¦é—´æ¥æ”¶é›†
        projects_dict = {}
        
        # ä»æ•°æ®æºæ”¶é›†é¡¹ç›®
        ds_query = """
        {
            publishedDatasources {
                projectName
                projectVizportalUrlId
            }
        }
        """
        ds_result = self.execute_query(ds_query)
        if "data" in ds_result and ds_result["data"]:
            for ds in (ds_result["data"].get("publishedDatasources") or []):
                if ds and ds.get("projectName"):
                    project_name = ds["projectName"]
                    if project_name and project_name not in projects_dict:
                        projects_dict[project_name] = {
                            "name": project_name,
                            "vizportalUrlId": ds.get("projectVizportalUrlId")
                        }
        
        # ä»å·¥ä½œç°¿æ”¶é›†é¡¹ç›®
        wb_query = """
        {
            workbooks {
                projectName
                projectVizportalUrlId
            }
        }
        """
        wb_result = self.execute_query(wb_query)
        if "data" in wb_result and wb_result["data"]:
            for wb in (wb_result["data"].get("workbooks") or []):
                if wb and wb.get("projectName"):
                    project_name = wb["projectName"]
                    if project_name and project_name not in projects_dict:
                        projects_dict[project_name] = {
                            "name": project_name,
                            "vizportalUrlId": wb.get("projectVizportalUrlId")
                        }
        
        # ç”Ÿæˆå”¯ä¸€ ID (ä½¿ç”¨ MD5 ä¿è¯ç¨³å®šæ€§)
        result = []
        for name, proj in projects_dict.items():
            # ä½¿ç”¨ MD5 ç”Ÿæˆç¨³å®šçš„ ID (å‰8ä½ä½œä¸º ID)
            import hashlib
            name_hash = hashlib.md5(name.encode('utf-8')).hexdigest()
            proj["id"] = f"project_{name_hash[:8]}"
            result.append(proj)
        
        return result
