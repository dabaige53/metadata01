"""
å­—æ®µåˆ†è¡¨è¿ç§»è„šæœ¬ V5
ç©¿é€ç»§æ‰¿å»é‡ç­–ç•¥ï¼š
- åŸå§‹å­—æ®µï¼šåŒæ•°æ®æºåŒåçš„å­—æ®µç»§æ‰¿æœ‰ upstream_column_id çš„é‚£æ¡çš„å»é‡é”®
- è®¡ç®—å­—æ®µï¼šåŒæ•°æ®æºåŒååŒå…¬å¼çš„åªä¿ç•™ä¸€ä¸ª unique
"""
import os
import sys
import uuid
import hashlib

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from backend.config import Config
from backend.models import (
    Base, UniqueRegularField, RegularField, 
    UniqueCalculatedField, CalculatedField,
    CalcFieldDependency, RegularFieldFullLineage, CalcFieldFullLineage,
    regular_field_to_view, calc_field_to_view
)

def get_session():
    engine = create_engine(f'sqlite:///{Config.DATABASE_PATH}', echo=False)
    Session = sessionmaker(bind=engine)
    return Session(), engine

def cleanup_tables(session):
    print("ğŸ§¹ æ¸…ç†æ—§è¡¨...")
    for t in ['regular_fields', 'unique_regular_fields', 'unique_calculated_fields', 
              'calculated_fields', 'regular_field_to_view', 'calc_field_to_view', 
              'calc_field_dependencies', 'regular_field_full_lineage', 'calc_field_full_lineage']:
        try:
            session.execute(text(f'DROP TABLE IF EXISTS {t}'))
        except: pass
    session.commit()

def create_tables(engine):
    print("ğŸ“¦ åˆ›å»ºå››è¡¨æ¶æ„...")
    Base.metadata.create_all(engine, tables=[
        UniqueRegularField.__table__,
        RegularField.__table__,
        UniqueCalculatedField.__table__,
        CalculatedField.__table__,
        CalcFieldDependency.__table__,
        RegularFieldFullLineage.__table__,
        CalcFieldFullLineage.__table__,
        regular_field_to_view,
        calc_field_to_view
    ])

def generate_uuid():
    return str(uuid.uuid4())

def get_formula_hash(formula):
    if not formula:
        return 'empty_' + generate_uuid()
    return hashlib.md5(formula.encode('utf-8')).hexdigest()

def migrate_regular_fields(session):
    """åŸå§‹å­—æ®µå»é‡ï¼šç©¿é€ç»§æ‰¿ç­–ç•¥"""
    print("\n[1/4] è¿ç§»åŸå§‹å­—æ®µï¼ˆç©¿é€ç»§æ‰¿ç­–ç•¥ï¼‰...")
    
    rows = session.execute(text("""
        SELECT * FROM fields 
        WHERE is_calculated = 0 OR is_calculated IS NULL
    """)).mappings().all()
    
    print(f"  - å¾…å¤„ç†å®ä¾‹: {len(rows)}")
    
    # ç¬¬ä¸€éï¼šæ„å»ºç»§æ‰¿æ˜ å°„ (datasource_id, name) -> upstream_column_id
    canonical_map = {}
    for row in rows:
        if row['upstream_column_id'] and row['datasource_id']:
            key = (row['datasource_id'], row['name'])
            if key not in canonical_map:
                canonical_map[key] = row['upstream_column_id']
    
    print(f"  - æ„å»ºç»§æ‰¿æ˜ å°„: {len(canonical_map)} ä¸ª")
    
    # ç¬¬äºŒéï¼šå»é‡
    unique_map = {} 
    new_unique_records = []
    new_instance_records = []
    
    stats = {'col': 0, 'inherited': 0, 'table': 0, 'ds': 0}
    
    for row in rows:
        # å°è¯•ç»§æ‰¿
        inherited_col = None
        if row['datasource_id'] and row['name']:
            inherited_col = canonical_map.get((row['datasource_id'], row['name']))
        
        # ç¡®å®šå»é‡é”®
        if row['upstream_column_id']:
            key = f"col::{row['upstream_column_id']}"
            stats['col'] += 1
        elif inherited_col:
            key = f"col::{inherited_col}"  # ç»§æ‰¿ï¼
            stats['inherited'] += 1
        elif row['table_id']:
            key = f"table::{row['table_id']}::{row['name']}"
            stats['table'] += 1
        elif row['datasource_id']:
            key = f"ds::{row['datasource_id']}::{row['name']}"
            stats['ds'] += 1
        else:
            key = f"orphan::{row['id']}"
        
        if key not in unique_map:
            unique_id = generate_uuid()
            unique_map[key] = unique_id
            
            # å¯¹äºç»§æ‰¿çš„ï¼Œä½¿ç”¨ç»§æ‰¿çš„ upstream_column_id
            actual_col_id = row['upstream_column_id'] or inherited_col
            
            new_unique_records.append({
                'id': unique_id,
                'name': row['name'],
                'upstream_column_id': actual_col_id,
                'upstream_column_name': row['upstream_column_name'],
                'table_id': row['table_id'],
                'remote_type': row['remote_type'],
                'description': row['description'],
                'created_at': row['created_at']
            })
        else:
            unique_id = unique_map[key]
            
        new_instance_records.append({
            'id': row['id'],
            'unique_id': unique_id,
            'name': row['name'],
            'data_type': row['data_type'],
            'remote_type': row['remote_type'],
            'description': row['description'],
            'table_id': row['table_id'],
            'upstream_column_id': row['upstream_column_id'],
            'upstream_column_name': row['upstream_column_name'],
            'datasource_id': row['datasource_id'],
            'workbook_id': row['workbook_id'],
            'role': row['role'],
            'aggregation': row['aggregation'],
            'is_hidden': row['is_hidden'],
            'folder_name': row['folder_name'],
            'fully_qualified_name': row['fully_qualified_name'],
            'caption': row['caption'],
            'semantic_role': row['semantic_role'],
            'default_format': row['default_format'],
            'remote_field_id': row['remote_field_id'],
            'remote_field_name': row['remote_field_name'],
            'created_at': row['created_at'],
            'updated_at': row['updated_at'],
            'usage_count': row['usage_count'],
            'metric_usage_count': row['metric_usage_count']
        })
    
    if new_unique_records:
        session.bulk_insert_mappings(UniqueRegularField, new_unique_records)
    if new_instance_records:
        session.bulk_insert_mappings(RegularField, new_instance_records)
    
    print(f"  - ç­–ç•¥åˆ†å¸ƒ: ç‰©ç†åˆ—={stats['col']}, ç»§æ‰¿={stats['inherited']}, è¡¨={stats['table']}, æ•°æ®æº={stats['ds']}")
    print(f"  âœ… åŸå§‹å­—æ®µ: {len(new_instance_records)} å®ä¾‹ -> {len(new_unique_records)} æ ‡å‡†å­—æ®µ")
    return len(new_instance_records), len(new_unique_records)

def migrate_calculated_fields(session):
    """è®¡ç®—å­—æ®µå»é‡ï¼šåŒæ•°æ®æºåŒååŒå…¬å¼åªä¿ç•™ä¸€ä¸ª"""
    print("\n[2/4] è¿ç§»è®¡ç®—å­—æ®µ...")
    
    # è·å–åµŒå…¥å¼æ•°æ®æºâ†’å‘å¸ƒå¼æ•°æ®æºæ˜ å°„
    ds_penetration = {}
    ds_rows = session.execute(text("""
        SELECT id, source_published_datasource_id FROM datasources WHERE source_published_datasource_id IS NOT NULL
    """)).fetchall()
    for ds_id, source_id in ds_rows:
        ds_penetration[ds_id] = source_id
    
    rows = session.execute(text("SELECT * FROM fields WHERE is_calculated = 1")).mappings().all()
    print(f"  - å¾…å¤„ç†å®ä¾‹: {len(rows)}")
    
    # å»é‡é”®: (ç©¿é€åçš„datasource_id, name, formula_hash)
    unique_map = {}
    new_unique_records = []
    new_instance_records = []
    
    for row in rows:
        formula = row['formula'] or ''
        formula_hash = get_formula_hash(formula)
        
        # ç©¿é€åˆ°å‘å¸ƒå¼æ•°æ®æº
        ds_id = row['datasource_id']
        if ds_id and ds_id in ds_penetration:
            ds_id = ds_penetration[ds_id]
        
        # å»é‡é”®: (name, formula_hash) - å…¨å±€å»é‡ï¼Œå¿½ç•¥æ•°æ®æºå·®å¼‚
        # åªè¦åå­—å’Œå…¬å¼ä¸€è‡´ï¼Œå°±è§†ä¸ºåŒä¸€ä¸ª"æ ‡å‡†æŒ‡æ ‡"
        name_clean = (row['name'] or '').strip()
        key = f"{name_clean}::{formula_hash}"
        
        if key not in unique_map:
            unique_id = generate_uuid()
            unique_map[key] = unique_id
            
            new_unique_records.append({
                'id': unique_id,
                'name': name_clean, # ä½¿ç”¨æ¸…æ´—åçš„åç§°
                'formula': formula,
                'formula_hash': formula_hash,
                'description': row['description'],
                'complexity_score': 0,
                'created_at': row['created_at']
            })
        else:
            unique_id = unique_map[key]
            
        new_instance_records.append({
            'id': row['id'],
            'unique_id': unique_id,
            'name': row['name'],
            'data_type': row['data_type'],
            'description': row['description'],
            'formula': formula,
            'formula_hash': formula_hash,
            'complexity_score': 0,
            'datasource_id': row['datasource_id'],
            'workbook_id': row['workbook_id'],
            'table_id': row['table_id'],
            'role': row['role'],
            'is_hidden': row['is_hidden'],
            'folder_name': row['folder_name'],
            'fully_qualified_name': row['fully_qualified_name'],
            'caption': row['caption'],
            'usage_count': row['usage_count'],
            'created_at': row['created_at'],
            'updated_at': row['updated_at']
        })
        
    if new_unique_records:
        session.bulk_insert_mappings(UniqueCalculatedField, new_unique_records)
    if new_instance_records:
        session.bulk_insert_mappings(CalculatedField, new_instance_records)

    print(f"  âœ… è®¡ç®—å­—æ®µ: {len(new_instance_records)} å®ä¾‹ -> {len(new_unique_records)} æ ‡å‡†æŒ‡æ ‡")
    return len(new_instance_records), len(new_unique_records)

def migrate_relations(session):
    print("\n[3/4] è¿ç§»å…³è”å…³ç³»...")
    
    session.execute(text("""
        INSERT INTO regular_field_to_view (field_id, view_id)
        SELECT fv.field_id, fv.view_id 
        FROM field_to_view fv
        JOIN fields f ON fv.field_id = f.id
        WHERE f.is_calculated = 0 OR f.is_calculated IS NULL
    """))
    
    session.execute(text("""
        INSERT INTO calc_field_to_view (field_id, view_id)
        SELECT fv.field_id, fv.view_id 
        FROM field_to_view fv
        JOIN fields f ON fv.field_id = f.id
        WHERE f.is_calculated = 1
    """))
    
    print("  âœ… è§†å›¾å…³è”è¿ç§»å®Œæˆ")
    
    session.execute(text("""
        INSERT INTO calc_field_dependencies (
            source_field_id, 
            dependency_regular_field_id,
            dependency_calc_field_id,
            dependency_name, 
            dependency_type
        )
        SELECT 
            fd.source_field_id,
            CASE WHEN dep.is_calculated = 0 OR dep.is_calculated IS NULL 
                 THEN fd.dependency_field_id ELSE NULL END,
            CASE WHEN dep.is_calculated = 1 
                 THEN fd.dependency_field_id ELSE NULL END,
            fd.dependency_name,
            fd.dependency_type
        FROM field_dependencies fd
        LEFT JOIN fields dep ON fd.dependency_field_id = dep.id
        WHERE fd.source_field_id IN (SELECT id FROM fields WHERE is_calculated = 1)
    """))
    
    print("  âœ… ä¾èµ–å…³ç³»è¿ç§»å®Œæˆ")

def update_statistics(session):
    """æ›´æ–°å¼•ç”¨è®¡æ•°å’Œä¾èµ–è®¡æ•°"""
    print("\n[3.5/4] æ›´æ–°ç»Ÿè®¡ä¿¡æ¯...")
    
    # æ›´æ–°å¼•ç”¨è®¡æ•° (è¢«å¤šå°‘ä¸ªè®¡ç®—å­—æ®µå¼•ç”¨)
    session.execute(text("""
        UPDATE calculated_fields SET reference_count = (
            SELECT COUNT(*) FROM calc_field_dependencies 
            WHERE calc_field_dependencies.dependency_calc_field_id = calculated_fields.id
        )
    """))
    
    # æ›´æ–°ä¾èµ–è®¡æ•° (ä¾èµ–äº†å¤šå°‘ä¸ªå­—æ®µ)
    session.execute(text("""
        UPDATE calculated_fields SET dependency_count = (
            SELECT COUNT(*) FROM calc_field_dependencies 
            WHERE calc_field_dependencies.source_field_id = calculated_fields.id
        )
    """))

    print("  ... è®¡ç®—å¤æ‚åº¦è¯„åˆ† ...")
    # Fetch all calculated fields
    rows = session.execute(text("SELECT id, formula, dependency_count FROM calculated_fields")).fetchall()
    
    updates = []
    for row in rows:
        fid = row.id
        formula = row.formula
        dep_count = row.dependency_count or 0
        
        score = 0
        if formula:
            # 1. Length Factor
            score += len(formula) / 50.0
            # 2. Structure Factor
            score += formula.count('\n') * 0.5
            # 3. Keywords
            keywords = {
                'FIXED': 5, 'INCLUDE': 4, 'EXCLUDE': 4, 'REGEXP': 3,
                'CASE': 2, 'IF': 1, 'IIF': 1, 'ZN': 1, 'ISNULL': 1,
                'DATE': 1, 'SPLIT': 2
            }
            upper_f = formula.upper()
            for kw, weight in keywords.items():
                score += upper_f.count(kw) * weight
        
        # 4. Dependency Factor
        score += dep_count * 2.0
        
        updates.append({'id': fid, 'score': round(score, 1)})
    
    if updates:
        session.execute(text("UPDATE calculated_fields SET complexity_score = :score WHERE id = :id"), updates)
        
    print(f"  âœ… ç»Ÿè®¡ä¿¡æ¯æ›´æ–°å®Œæˆ (æ›´æ–°äº† {len(updates)} ä¸ªå¤æ‚åº¦è¯„åˆ†)")

def migrate_lineage(session):
    print("\n[4/4] è¿ç§»è¡€ç¼˜æ•°æ®...")
    
    # === åŸå§‹å­—æ®µè¡€ç¼˜ï¼šä¿æŒåŸæœ‰é€»è¾‘ï¼ˆåŸºäºæ•°æ®æºè¿æ¥ï¼‰ ===
    session.execute(text("""
        INSERT INTO regular_field_full_lineage (
            field_id, table_id, datasource_id, workbook_id, lineage_type, lineage_path
        )
        SELECT fl.field_id, fl.table_id, fl.datasource_id, fl.workbook_id, fl.lineage_type, fl.lineage_path
        FROM field_full_lineage fl
        JOIN fields f ON fl.field_id = f.id
        WHERE f.is_calculated = 0 OR f.is_calculated IS NULL
    """))
    
    # === è®¡ç®—å­—æ®µè¡€ç¼˜ï¼šä¿®å¤é€»è¾‘ ===
    # 1. å·¥ä½œç°¿è¡€ç¼˜åŸºäºå®ä¾‹å½’å± (calculated_fields.workbook_id)
    # 2. åŒæ—¶åŒ…å«å®é™…ä½¿ç”¨ (calc_field_to_view) çš„å·¥ä½œç°¿
    
    # æ­¥éª¤1ï¼šåŸºäºå®ä¾‹å½’å± (calculated_fields.workbook_id) æ’å…¥è¡€ç¼˜
    session.execute(text("""
        INSERT INTO calc_field_full_lineage (
            field_id, table_id, datasource_id, workbook_id, lineage_type, lineage_path
        )
        SELECT DISTINCT 
            cf.id as field_id,
            cf.table_id,
            cf.datasource_id,
            cf.workbook_id,
            'direct' as lineage_type,
            'CalcField -> Workbook (ownership)' as lineage_path
        FROM calculated_fields cf
        WHERE cf.workbook_id IS NOT NULL
    """))
    
    # æ­¥éª¤2ï¼šåŸºäºå®é™…ä½¿ç”¨å…³ç³» (calc_field_to_view) è¡¥å……é¢å¤–çš„å·¥ä½œç°¿è¡€ç¼˜
    # ï¼ˆæŸäº›æƒ…å†µä¸‹ï¼Œè®¡ç®—å­—æ®µå¯èƒ½è¢«å…¶ä»–å·¥ä½œç°¿çš„è§†å›¾ä½¿ç”¨ï¼‰
    session.execute(text("""
        INSERT OR IGNORE INTO calc_field_full_lineage (
            field_id, table_id, datasource_id, workbook_id, lineage_type, lineage_path
        )
        SELECT DISTINCT 
            cf.id as field_id,
            cf.table_id,
            cf.datasource_id,
            v.workbook_id,
            'direct' as lineage_type,
            'CalcField -> View -> Workbook (actual usage)' as lineage_path
        FROM calculated_fields cf
        JOIN calc_field_to_view cfv ON cf.id = cfv.field_id
        JOIN views v ON cfv.view_id = v.id
        WHERE v.workbook_id IS NOT NULL
          AND NOT EXISTS (
              SELECT 1 FROM calc_field_full_lineage fl 
              WHERE fl.field_id = cf.id AND fl.workbook_id = v.workbook_id
          )
    """))
    
    print("  âœ… è¡€ç¼˜æ•°æ®è¿ç§»å®Œæˆï¼ˆè®¡ç®—å­—æ®µè¡€ç¼˜åŸºäºå®é™…ä½¿ç”¨ï¼‰")

    print("\n[4.5/4] è¡¥å…¨æ‰€æœ‰æƒè¡€ç¼˜ (Ownership Lineage)...")
    # ä¿®å¤ï¼šå¯¹äºæ²¡æœ‰ä½¿ç”¨çš„å­—æ®µï¼Œä¹Ÿéœ€è¦è®°å½•å…¶å½’å±çš„å·¥ä½œç°¿/æ•°æ®æºè¡€ç¼˜
    # è¿™æ ·åœ¨æŸ¥è¯¢è¡€ç¼˜æ—¶ï¼Œå³ä½¿ usage_count=0ï¼Œä¹Ÿèƒ½çœ‹åˆ°å®ƒå±äºå“ªä¸ªå·¥ä½œç°¿
    session.execute(text("""
        INSERT INTO regular_field_full_lineage (
            field_id, datasource_id, workbook_id, lineage_type, lineage_path
        )
        SELECT 
            rf.id, rf.datasource_id, rf.workbook_id, 'direct', 'Ownership'
        FROM regular_fields rf
        WHERE rf.workbook_id IS NOT NULL 
          AND NOT EXISTS (
              SELECT 1 FROM regular_field_full_lineage fl 
              WHERE fl.field_id = rf.id AND fl.workbook_id = rf.workbook_id
          )
    """))
    print("  âœ… æ‰€æœ‰æƒè¡€ç¼˜è¡¥å…¨å®Œæˆ")

def verify_no_duplicates(session):
    """éªŒè¯å»é‡åæ— æ®‹ç•™é‡å¤"""
    print("\nğŸ” éªŒè¯å»é‡æ•ˆæœ...")
    
    # åŸå§‹å­—æ®µï¼šåŒdsåŒnameåº”è¯¥åªæœ‰ 1 ä¸ª unique
    result = session.execute(text("""
        SELECT COUNT(*) FROM (
            SELECT datasource_id, name, COUNT(DISTINCT unique_id) as uid_cnt
            FROM regular_fields
            GROUP BY datasource_id, name
            HAVING COUNT(DISTINCT unique_id) > 1
        )
    """)).scalar()
    
    if result == 0:
        print("  âœ… åŸå§‹å­—æ®µæ— æ®‹ç•™é‡å¤")
    else:
        print(f"  âš ï¸ åŸå§‹å­—æ®µä»æœ‰ {result} ç»„æ®‹ç•™é‡å¤")
    
    # è®¡ç®—å­—æ®µï¼šåŒdsåŒnameåŒformulaåº”è¯¥åªæœ‰ 1 ä¸ª unique
    result2 = session.execute(text("""
        SELECT COUNT(*) FROM (
            SELECT name, formula, COUNT(DISTINCT unique_id) as uid_cnt
            FROM calculated_fields
            GROUP BY name, formula
            HAVING COUNT(DISTINCT unique_id) > 1
        )
    """)).scalar()
    
    if result2 == 0:
        print("  âœ… è®¡ç®—å­—æ®µæ— æ®‹ç•™é‡å¤")
    else:
        print(f"  âš ï¸ è®¡ç®—å­—æ®µä»æœ‰ {result2} ç»„æ®‹ç•™é‡å¤")
    
    return result == 0 and result2 == 0

def main():
    print("ğŸš€ å¼€å§‹å››è¡¨æ¶æ„è¿ç§» V5 (ç©¿é€ç»§æ‰¿ç­–ç•¥)...")
    
    session, engine = get_session()
    
    try:
        cleanup_tables(session)
        create_tables(engine)
        
        r_inst, r_uniq = migrate_regular_fields(session)
        c_inst, c_uniq = migrate_calculated_fields(session)
        migrate_relations(session)
        update_statistics(session)
        migrate_lineage(session)
        
        session.commit()
        
        is_valid = verify_no_duplicates(session)
        
        print("\n" + "=" * 50)
        print("âœ¨ è¿ç§»å®Œæˆï¼")
        print(f"  åŸå§‹å­—æ®µ: {r_inst} å®ä¾‹ -> {r_uniq} æ ‡å‡†å­—æ®µ")
        print(f"  è®¡ç®—å­—æ®µ: {c_inst} å®ä¾‹ -> {c_uniq} æ ‡å‡†æŒ‡æ ‡")
        print(f"  éªŒè¯ç»“æœ: {'âœ… æ— æ®‹ç•™é‡å¤' if is_valid else 'âš ï¸ æœ‰æ®‹ç•™é‡å¤'}")
        print("=" * 50)
        
    except Exception as e:
        session.rollback()
        print(f"\nâŒ è¿ç§»å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise
    finally:
        session.close()

if __name__ == "__main__":
    main()
