"""
Tableau Metadata API æ•°æ®åŒæ­¥æ¨¡å—
ä» Tableau Server æŠ“å–å…ƒæ•°æ®å¹¶å­˜å…¥æœ¬åœ°æ•°æ®åº“
"""
import os
import sys
import json
import requests
import hashlib
from collections import defaultdict
from datetime import datetime
from typing import Optional, List, Dict, Any
from sqlalchemy import select, text
import re

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from backend.config import Config
from backend.models import (
    Base, get_engine, init_db, get_session,
    Database, DBTable, DBColumn, Field, Datasource, Workbook, View,
    TableauUser, Project,
    table_to_datasource, datasource_to_workbook, field_to_view, CalculatedField, SyncLog,
    FieldDependency, Metric
)


class TableauMetadataClient:
    """Tableau Metadata API å®¢æˆ·ç«¯"""
    
    def __init__(self, base_url: str, username: str, password: str):
        self.base_url = base_url.rstrip('/')
        self.username = username
        self.password = password
        self.auth_token: Optional[str] = None
        self.site_id: Optional[str] = None
        self.api_version = "3.10"
    
    def sign_in(self) -> bool:
        """ç™»å½•è·å–è®¤è¯ token"""
        signin_url = f"{self.base_url}/api/{self.api_version}/auth/signin"
        
        payload = {
            "credentials": {
                "name": self.username,
                "password": self.password,
                "site": {"contentUrl": ""}
            }
        }
        
        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json"
        }
        
        try:
            response = requests.post(signin_url, headers=headers, json=payload, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                credentials = data.get("credentials", {})
                self.auth_token = credentials.get("token")
                self.site_id = credentials.get("site", {}).get("id")
                print(f"âœ… ç™»å½•æˆåŠŸ (Token: {self.auth_token[:20]}...)")
                return True
            else:
                print(f"âŒ ç™»å½•å¤±è´¥: {response.text}")
                return False
        except Exception as e:
            print(f"âŒ ç™»å½•å¼‚å¸¸: {e}")
            return False
    
    def sign_out(self):
        """ç™»å‡ºé‡Šæ”¾ token"""
        if not self.auth_token:
            return
        
        signout_url = f"{self.base_url}/api/{self.api_version}/auth/signout"
        headers = {"X-Tableau-Auth": self.auth_token}
        
        try:
            response = requests.post(signout_url, headers=headers, timeout=30)
            if response.status_code == 204:
                print("âœ… å·²ç™»å‡º")
        except Exception as e:
            print(f"ç™»å‡ºå¼‚å¸¸: {e}")
        finally:
            self.auth_token = None
    
    def execute_query(self, query: str) -> Dict[str, Any]:
        """æ‰§è¡Œ GraphQL æŸ¥è¯¢"""
        if not self.auth_token:
            raise RuntimeError("æœªç™»å½•ï¼Œè¯·å…ˆè°ƒç”¨ sign_in()")
        
        url = f"{self.base_url}/api/metadata/graphql"
        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json",
            "X-Tableau-Auth": self.auth_token
        }
        
        response = requests.post(url, headers=headers, json={"query": query}, timeout=60)
        
        if response.status_code == 200:
            return response.json()
        else:
            raise RuntimeError(f"GraphQL æŸ¥è¯¢å¤±è´¥: {response.status_code} - {response.text}")
    
    def fetch_views_usage(self) -> Dict[str, int]:
        """ä» REST API è·å–è§†å›¾ä½¿ç”¨ç»Ÿè®¡ (REST API)"""
        if not self.auth_token or not self.site_id:
            raise RuntimeError("æœªç™»å½•ï¼Œè¯·å…ˆè°ƒç”¨ sign_in()")
        
        # REST API endpoint for views
        url = f"{self.base_url}/api/{self.api_version}/sites/{self.site_id}/views"
        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json",
            "X-Tableau-Auth": self.auth_token
        }
        
        usage_map = {}
        page_number = 1
        page_size = 100
        
        print(f"  æ­£åœ¨è°ƒç”¨ REST API è·å–è®¿é—®ç»Ÿè®¡: {url}")
        
        while True:
            params = {
                "pageNumber": page_number,
                "pageSize": page_size,
                "includeUsageStatistics": "true"
            }
            
            try:
                response = requests.get(url, headers=headers, params=params, timeout=30)
                
                if response.status_code != 200:
                    print(f"  âŒ REST API è·å–å¤±è´¥: {response.status_code} - {response.text}")
                    break
                
                data = response.json()
                views = data.get("views", {}).get("view", [])
                
                if not views:
                    break
                
                for view in views:
                    luid = view.get("id")
                    usage = view.get("usage", {})
                    # usage å¯èƒ½æ˜¯ Noneï¼Œä¹Ÿå¯èƒ½æ²¡æœ‰ totalViewCount
                    if usage:
                        total_count = usage.get("totalViewCount", 0)
                        if luid:
                            usage_map[luid] = int(total_count)
                
                # Check pagination
                pagination = data.get("pagination", {})
                total_available = int(pagination.get("totalAvailable", 0))
                
                print(f"    - Page {page_number}: è·å– {len(views)} ä¸ªè§†å›¾, æ€»è¿›åº¦ {len(usage_map)}/{total_available}")
                
                if len(usage_map) >= total_available or len(views) < page_size:
                    break
                    
                page_number += 1
                
            except Exception as e:
                print(f"  âŒ è·å–è§†å›¾ç»Ÿè®¡å¼‚å¸¸: {e}")
                break
                
        return usage_map    
    def fetch_databases(self) -> List[Dict]:
        """è·å–æ‰€æœ‰æ•°æ®åº“ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        query = """
        {
            databaseServers {
                id
                luid
                name
                connectionType
                hostName
                port
                service
                description
                isCertified
                certificationNote
            }
        }
        """
        result = self.execute_query(query)
        # å…¼å®¹å¤„ç†ï¼šå…ˆå°è¯• databaseServersï¼Œå¤±è´¥åˆ™å›é€€åˆ° databases
        data = result.get("data", {})
        servers = data.get("databaseServers")
        if servers is not None:
            return servers
        # å›é€€åˆ°æ—§æŸ¥è¯¢
        return self._fetch_databases_fallback()
    
    def _fetch_databases_fallback(self) -> List[Dict]:
        """å›é€€ï¼šä½¿ç”¨æ—§ç‰ˆæŸ¥è¯¢è·å–æ•°æ®åº“"""
        query = """
        {
            databases {
                id
                name
                connectionType
            }
        }
        """
        result = self.execute_query(query)
        return result.get("data", {}).get("databases", [])
    
    def fetch_tables(self) -> List[Dict]:
        """è·å–æ‰€æœ‰æ•°æ®è¡¨ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        query = """
        {
            databaseTables {
                id
                luid
                name
                schema
                fullName
                tableType
                description
                isEmbedded
                isCertified
                certificationNote
                projectName
                database {
                    id
                    name
                    connectionType
                }
                columns {
                    id
                    name
                    remoteType
                    description
                    isNullable
                }
            }
        }
        """
        result = self.execute_query(query)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ï¼ˆæŸäº›å­—æ®µå¯èƒ½ä¸è¢«æ”¯æŒï¼‰
        if "errors" in result:
            print(f"  âš ï¸ GraphQL è­¦å‘Š: {result['errors']}")
            # å°è¯•ç®€åŒ–æŸ¥è¯¢
            return self._fetch_tables_fallback()
        
        return result.get("data", {}).get("databaseTables", [])
    
    def _fetch_tables_fallback(self) -> List[Dict]:
        """å›é€€ï¼šä½¿ç”¨ç®€åŒ–æŸ¥è¯¢è·å–è¡¨ï¼ˆåŒ…å«åˆ—ä¿¡æ¯ï¼‰"""
        query = """
        {
            databaseTables {
                id
                name
                schema
                fullName
                isEmbedded
                database {
                    id
                    name
                    connectionType
                }
                columns {
                    id
                    name
                    remoteType
                    description
                    isNullable
                }
            }
        }
        """
        result = self.execute_query(query)
        return result.get("data", {}).get("databaseTables", [])
    
    def fetch_datasources(self) -> List[Dict]:
        """è·å–æ‰€æœ‰å·²å‘å¸ƒæ•°æ®æºï¼ˆå¢å¼ºç‰ˆï¼‰"""
        query = """
        {
            publishedDatasources {
                id
                luid
                name
                description
                uri
                projectName
                hasExtracts
                extractLastRefreshTime
                extractLastIncrementalUpdateTime
                extractLastUpdateTime
                isCertified
                certificationNote
                certifierDisplayName
                containsUnsupportedCustomSql
                hasActiveWarning
                createdAt
                updatedAt
                owner {
                    id
                    username
                    name
                }
                upstreamTables {
                    id
                    name
                }
            }
        }
        """
        result = self.execute_query(query)
        
        # æ£€æŸ¥é”™è¯¯å¹¶å›é€€
        if "errors" in result:
            print(f"  âš ï¸ GraphQL è­¦å‘Š: {result['errors']}")
            return self._fetch_datasources_fallback()
        
        return result.get("data", {}).get("publishedDatasources", [])
    
    def _fetch_datasources_fallback(self) -> List[Dict]:
        """å›é€€ï¼šä½¿ç”¨ç®€åŒ–æŸ¥è¯¢è·å–æ•°æ®æº"""
        query = """
        {
            publishedDatasources {
                id
                name
                projectName
                hasExtracts
                extractLastRefreshTime
                isCertified
                owner {
                    username
                }
                upstreamTables {
                    id
                    name
                }
            }
        }
        """
        result = self.execute_query(query)
        return result.get("data", {}).get("publishedDatasources", [])
    
    def fetch_workbooks(self) -> List[Dict]:
        """è·å–æ‰€æœ‰å·¥ä½œç°¿ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        query = """
        {
            workbooks {
                id
                luid
                name
                description
                uri
                projectName
                createdAt
                updatedAt
                containsUnsupportedCustomSql
                hasActiveWarning
                owner {
                    id
                    username
                    name
                }
                upstreamDatasources {
                    id
                    name
                }
                sheets {
                    id
                    luid
                    name
                    path
                    index
                    createdAt
                    updatedAt
                }
                dashboards {
                    id
                    luid
                    name
                    path
                    index
                    createdAt
                    updatedAt
                }
            }
        }
        """
        result = self.execute_query(query)
        
        # æ£€æŸ¥é”™è¯¯å¹¶å›é€€
        if "errors" in result:
            print(f"  âš ï¸ GraphQL è­¦å‘Š: {result['errors']}")
            return self._fetch_workbooks_fallback()
        
        return result.get("data", {}).get("workbooks", [])
    
    def _fetch_workbooks_fallback(self) -> List[Dict]:
        """å›é€€ï¼šä½¿ç”¨ç®€åŒ–æŸ¥è¯¢è·å–å·¥ä½œç°¿"""
        query = """
        {
            workbooks {
                id
                name
                projectName
                createdAt
                updatedAt
                owner {
                    username
                }
                upstreamDatasources {
                    id
                    name
                }
                sheets {
                    id
                    luid
                    name
                }
                dashboards {
                    id
                    luid
                    name
                }
            }
        }
        """
        result = self.execute_query(query)
        return result.get("data", {}).get("workbooks", [])
    
    def fetch_fields(self) -> List[Dict]:
        """è·å–æ‰€æœ‰å­—æ®µï¼ˆé€šè¿‡æ•°æ®æºï¼‰"""
        query = """
        {
            publishedDatasources {
                id
                name
                fields {
                    id
                    name
                    description
                }
            }
        }
        """
        result = self.execute_query(query)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        if "errors" in result:
            print(f"  âš ï¸ GraphQL é”™è¯¯: {result['errors']}")
            return []
        
        data = result.get("data")
        if data is None:
            print(f"  âš ï¸ æœªè·å–åˆ°æ•°æ®: {result}")
            return []
            
        datasources = data.get("publishedDatasources") or []
        
        # å±•å¹³å­—æ®µåˆ—è¡¨
        all_fields = []
        for ds in datasources:
            if not ds:
                continue
            ds_id = ds.get("id")
            ds_name = ds.get("name")
            fields = ds.get("fields") or []
            for field in fields:
                if field and field.get("id"):
                    field["datasource_id"] = ds_id
                    field["datasource_name"] = ds_name
                    all_fields.append(field)
        
        return all_fields
    
    def fetch_calculated_fields(self) -> List[Dict]:
        """è·å–æ‰€æœ‰è®¡ç®—å­—æ®µ"""
        query = """
        {
            calculatedFields {
                id
                name
                description
                formula
                dataType
                role
                datasource {
                    id
                    name
                }
            }
        }
        """
        result = self.execute_query(query)
        
        # æ£€æŸ¥é”™è¯¯
        if "errors" in result:
            print(f"  âš ï¸ GraphQL é”™è¯¯: {result['errors']}")
            return []
        
        data = result.get("data")
        if data is None:
            return []
        
        calc_fields = data.get("calculatedFields") or []
        
        # å¤„ç†æ•°æ®ï¼Œæ·»åŠ  datasource_id
        for cf in calc_fields:
            if cf and cf.get("datasource"):
                cf["datasource_id"] = cf["datasource"].get("id")
        
        return calc_fields
    
    def fetch_views_with_fields(self) -> List[Dict]:
        """è·å–è§†å›¾åŠå…¶ä½¿ç”¨çš„å­—æ®µï¼ˆç”¨äºå¡«å…… field_to_view å…³è”è¡¨ï¼‰"""
        query = """
        {
            sheets {
                id
                name
                workbook {
                    id
                    name
                }
                sheetFieldInstances {
                    id
                    name
                    datasource {
                        id
                    }
                }
            }
        }
        """
        result = self.execute_query(query)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        if "errors" in result:
            print(f"  âš ï¸ GraphQL é”™è¯¯ (sheetFieldInstances): {result['errors']}")
            # å°è¯•å¤‡ç”¨æŸ¥è¯¢
            return self._fetch_views_with_fields_fallback()
        
        data = result.get("data")
        if data is None:
            print(f"  âš ï¸ æœªè·å–åˆ°æ•°æ®")
            return []
        
        sheets = data.get("sheets") or []
        
        # æ„å»ºè§†å›¾â†’å­—æ®µæ˜ å°„
        view_fields = []
        for sheet in sheets:
            if not sheet:
                continue
            view_id = sheet.get("id")
            view_name = sheet.get("name")
            workbook = sheet.get("workbook") or {}
            fields = sheet.get("sheetFieldInstances") or []
            
            for field in fields:
                if field and field.get("id"):
                    view_fields.append({
                        "view_id": view_id,
                        "view_name": view_name,
                        "workbook_id": workbook.get("id"),
                        "field_id": field.get("id"),
                        "field_name": field.get("name"),
                        "datasource_id": (field.get("datasource") or {}).get("id")
                    })
        
        return view_fields
    
    def _fetch_views_with_fields_fallback(self) -> List[Dict]:
        """å¤‡ç”¨æ–¹æ³•ï¼šé€šè¿‡å·¥ä½œç°¿çš„æ•°æ®æºå…³ç³»é—´æ¥è·å–"""
        # ç”±äº Tableau API é™åˆ¶ï¼Œæˆ‘ä»¬é‡‡ç”¨ç®€åŒ–ç­–ç•¥ï¼š
        # é€šè¿‡ calculatedFields çš„ datasource å…³ç³»æ¥å»ºç«‹å­—æ®µâ†’è§†å›¾çš„é—´æ¥å…³è”
        query = """
        {
            workbooks {
                id
                name
                sheets {
                    id
                    name
                }
                upstreamDatasources {
                    id
                    name
                }
            }
        }
        """
        result = self.execute_query(query)
        
        if "errors" in result:
            print(f"  âš ï¸ å¤‡ç”¨æŸ¥è¯¢ä¹Ÿå¤±è´¥: {result['errors']}")
            return []
        
        data = result.get("data")
        if data is None:
            return []
        
        workbooks = data.get("workbooks") or []
        
        # è·å–æ•°æ®æºåˆ°å­—æ®µçš„æ˜ å°„
        ds_to_fields = {}
        fields_result = self.execute_query("""
        {
            publishedDatasources {
                id
                fields {
                    id
                    name
                }
            }
        }
        """)
        if "data" in fields_result and fields_result["data"]:
            for ds in (fields_result["data"].get("publishedDatasources") or []):
                if ds:
                    ds_to_fields[ds["id"]] = ds.get("fields") or []
        
        # æ„å»ºè§†å›¾â†’å­—æ®µå…³è”
        view_fields = []
        for wb in workbooks:
            if not wb:
                continue
            sheets = wb.get("sheets") or []
            datasources = wb.get("upstreamDatasources") or []
            
            for sheet in sheets:
                if not sheet:
                    continue
                # å°†æ•°æ®æºçš„å­—æ®µå…³è”åˆ°è§†å›¾
                for ds in datasources:
                    if not ds:
                        continue
                    for field in ds_to_fields.get(ds.get("id"), []):
                        if field and field.get("id"):
                            view_fields.append({
                                "view_id": sheet.get("id"),
                                "view_name": sheet.get("name"),
                                "workbook_id": wb.get("id"),
                                "field_id": field.get("id"),
                                "field_name": field.get("name")
                            })
        
        return view_fields


    def fetch_users(self) -> List[Dict]:
        """è·å–æ‰€æœ‰ Tableau ç”¨æˆ·"""
        query = """
        {
            tableauUsers {
                id
                luid
                name
                username
                email
                domain
                siteRole
            }
        }
        """
        result = self.execute_query(query)
        
        # æ£€æŸ¥é”™è¯¯
        if "errors" in result:
            print(f"  âš ï¸ GraphQL è­¦å‘Š (users): {result['errors']}")
            # å°è¯•ç®€åŒ–æŸ¥è¯¢
            return self._fetch_users_fallback()
        
        return result.get("data", {}).get("tableauUsers", [])
    
    def _fetch_users_fallback(self) -> List[Dict]:
        """å›é€€ï¼šé€šè¿‡ owner å…³ç³»æ”¶é›†ç”¨æˆ·"""
        users_dict = {}
        
        # ä»æ•°æ®æºæ”¶é›†ç”¨æˆ·
        ds_query = """
        {
            publishedDatasources {
                owner {
                    id
                    username
                    name
                }
            }
        }
        """
        ds_result = self.execute_query(ds_query)
        if "data" in ds_result and ds_result["data"]:
            for ds in (ds_result["data"].get("publishedDatasources") or []):
                if ds and ds.get("owner"):
                    owner = ds["owner"]
                    if owner.get("id"):
                        users_dict[owner["id"]] = {
                            "id": owner.get("id"),
                            "name": owner.get("name"),
                            "username": owner.get("username")
                        }
        
        # ä»å·¥ä½œç°¿æ”¶é›†ç”¨æˆ·
        wb_query = """
        {
            workbooks {
                owner {
                    id
                    username
                    name
                }
            }
        }
        """
        wb_result = self.execute_query(wb_query)
        if "data" in wb_result and wb_result["data"]:
            for wb in (wb_result["data"].get("workbooks") or []):
                if wb and wb.get("owner"):
                    owner = wb["owner"]
                    if owner.get("id"):
                        users_dict[owner["id"]] = {
                            "id": owner.get("id"),
                            "name": owner.get("name"),
                            "username": owner.get("username")
                        }
        
        return list(users_dict.values())
    
    def fetch_projects(self) -> List[Dict]:
        """è·å–æ‰€æœ‰ Tableau é¡¹ç›®"""
        # é€šè¿‡æ•°æ®æºå’Œå·¥ä½œç°¿çš„ projectName æ”¶é›†é¡¹ç›®ä¿¡æ¯
        # æ³¨æ„ï¼šTableau Metadata API æ²¡æœ‰ç›´æ¥çš„ projects æŸ¥è¯¢ï¼Œéœ€è¦é—´æ¥æ”¶é›†
        projects_dict = {}
        
        # ä»æ•°æ®æºæ”¶é›†é¡¹ç›®
        ds_query = """
        {
            publishedDatasources {
                projectName
                projectVizportalUrlId
            }
        }
        """
        ds_result = self.execute_query(ds_query)
        if "data" in ds_result and ds_result["data"]:
            for ds in (ds_result["data"].get("publishedDatasources") or []):
                if ds and ds.get("projectName"):
                    project_name = ds["projectName"]
                    if project_name and project_name not in projects_dict:
                        projects_dict[project_name] = {
                            "name": project_name,
                            "vizportalUrlId": ds.get("projectVizportalUrlId")
                        }
        
        # ä»å·¥ä½œç°¿æ”¶é›†é¡¹ç›®
        wb_query = """
        {
            workbooks {
                projectName
                projectVizportalUrlId
            }
        }
        """
        wb_result = self.execute_query(wb_query)
        if "data" in wb_result and wb_result["data"]:
            for wb in (wb_result["data"].get("workbooks") or []):
                if wb and wb.get("projectName"):
                    project_name = wb["projectName"]
                    if project_name and project_name not in projects_dict:
                        projects_dict[project_name] = {
                            "name": project_name,
                            "vizportalUrlId": wb.get("projectVizportalUrlId")
                        }
        
        # ç”Ÿæˆå”¯ä¸€ ID (ä½¿ç”¨ MD5 ä¿è¯ç¨³å®šæ€§)
        result = []
        for name, proj in projects_dict.items():
            # ä½¿ç”¨ MD5 ç”Ÿæˆç¨³å®šçš„ ID (å‰8ä½ä½œä¸º ID)
            import hashlib
            name_hash = hashlib.md5(name.encode('utf-8')).hexdigest()
            proj["id"] = f"project_{name_hash[:8]}"
            result.append(proj)
        
        return result


class MetadataSync:
    """å…ƒæ•°æ®åŒæ­¥ç®¡ç†å™¨"""
    
    def __init__(self, client: TableauMetadataClient, db_path: str = None):
        self.client = client
        self.db_path = db_path or Config.DATABASE_PATH
        self.engine = get_engine(self.db_path)
        self.session = get_session(self.engine)
        self.sync_log: Optional[SyncLog] = None
    
    def _start_sync_log(self, sync_type: str):
        """å¼€å§‹åŒæ­¥æ—¥å¿—"""
        self.sync_log = SyncLog(
            sync_type=sync_type,
            status="running",
            started_at=datetime.now(),
            records_synced=0
        )
        self.session.add(self.sync_log)
        self.session.commit()
    
    def _complete_sync_log(self, records: int, error: str = None):
        """å®ŒæˆåŒæ­¥æ—¥å¿—"""
        if self.sync_log:
            self.sync_log.status = "error" if error else "completed"
            self.sync_log.completed_at = datetime.now()
            self.sync_log.records_synced = records
            self.sync_log.error_message = error
            self.session.commit()
    
    def sync_databases(self) -> int:
        """åŒæ­¥æ•°æ®åº“ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        print("\nğŸ“¦ åŒæ­¥æ•°æ®åº“...")
        self._start_sync_log("databases")
        
        try:
            databases = self.client.fetch_databases()
            count = 0
            
            for db_data in databases:
                db = self.session.query(Database).filter_by(id=db_data["id"]).first()
                if not db:
                    db = Database(id=db_data["id"])
                    self.session.add(db)
                
                db.name = db_data.get("name", "")
                db.luid = db_data.get("luid")
                db.connection_type = db_data.get("connectionType", "")
                db.host_name = db_data.get("hostName")
                db.port = db_data.get("port")
                db.service = db_data.get("service")
                db.description = db_data.get("description")
                db.is_certified = db_data.get("isCertified", False)
                db.certification_note = db_data.get("certificationNote")
                db.updated_at = datetime.now()
                count += 1
            
            self.session.commit()
            self._complete_sync_log(count)
            print(f"  âœ… åŒæ­¥ {count} ä¸ªæ•°æ®åº“")
            return count
            
        except Exception as e:
            self.session.rollback()
            self._complete_sync_log(0, str(e))
            print(f"  âŒ åŒæ­¥å¤±è´¥: {e}")
            return 0
    
    def sync_tables(self) -> int:
        """åŒæ­¥æ•°æ®è¡¨ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        print("\nğŸ“‹ åŒæ­¥æ•°æ®è¡¨...")
        self._start_sync_log("tables")
        
        try:
            tables = self.client.fetch_tables()
            table_count = 0
            column_count = 0
            
            for t_data in tables:
                table = self.session.query(DBTable).filter_by(id=t_data["id"]).first()
                if not table:
                    table = DBTable(id=t_data["id"])
                    self.session.add(table)
                
                table.name = t_data.get("name", "")
                table.luid = t_data.get("luid")
                table.schema = t_data.get("schema", "")
                table.full_name = t_data.get("fullName", "")
                table.table_type = t_data.get("tableType")
                table.description = t_data.get("description")
                table.is_embedded = t_data.get("isEmbedded", False)
                table.is_certified = t_data.get("isCertified", False)
                table.certification_note = t_data.get("certificationNote")
                table.project_name = t_data.get("projectName")
                
                # å…³è”æ•°æ®åº“
                db_info = t_data.get("database", {})
                if db_info:
                    table.database_id = db_info.get("id")
                    table.connection_type = db_info.get("connectionType", "")
                
                table_count += 1
                
                # åŒæ­¥åˆ—ä¿¡æ¯
                columns = t_data.get("columns", [])
                for col_data in columns:
                    if not col_data or not col_data.get("id"):
                        continue
                    
                    col = self.session.query(DBColumn).filter_by(id=col_data["id"]).first()
                    if not col:
                        col = DBColumn(id=col_data["id"])
                        self.session.add(col)
                    
                    col.name = col_data.get("name", "")
                    col.remote_type = col_data.get("remoteType")
                    col.description = col_data.get("description")
                    col.is_nullable = col_data.get("isNullable")
                    col.table_id = t_data["id"]
                    column_count += 1
            
            self.session.commit()
            self._complete_sync_log(table_count)
            print(f"  âœ… åŒæ­¥ {table_count} ä¸ªæ•°æ®è¡¨, {column_count} ä¸ªåˆ—")
            return table_count
            
        except Exception as e:
            self.session.rollback()
            self._complete_sync_log(0, str(e))
            print(f"  âŒ åŒæ­¥å¤±è´¥: {e}")
            return 0
    
    def sync_datasources(self) -> int:
        """åŒæ­¥æ•°æ®æºï¼ˆå¢å¼ºç‰ˆï¼‰"""
        print("\nğŸ”— åŒæ­¥æ•°æ®æº...")
        self._start_sync_log("datasources")
        
        try:
            datasources = self.client.fetch_datasources()
            count = 0
            
            for ds_data in datasources:
                ds = self.session.query(Datasource).filter_by(id=ds_data["id"]).first()
                if not ds:
                    ds = Datasource(id=ds_data["id"])
                    self.session.add(ds)
                
                ds.name = ds_data.get("name", "")
                ds.luid = ds_data.get("luid")
                ds.description = ds_data.get("description")
                ds.uri = ds_data.get("uri")
                ds.project_name = ds_data.get("projectName", "")
                ds.has_extract = ds_data.get("hasExtracts", False)
                ds.is_certified = ds_data.get("isCertified", False)
                ds.certification_note = ds_data.get("certificationNote")
                ds.certifier_display_name = ds_data.get("certifierDisplayName")
                ds.contains_unsupported_custom_sql = ds_data.get("containsUnsupportedCustomSql", False)
                ds.has_active_warning = ds_data.get("hasActiveWarning", False)
                
                owner = ds_data.get("owner", {})
                if owner:
                    ds.owner = owner.get("username", "")
                    ds.owner_id = owner.get("id")
                
                # è§£ææ—¶é—´å­—æ®µ
                for time_field, attr_name in [
                    ("extractLastRefreshTime", "extract_last_refresh_time"),
                    ("extractLastIncrementalUpdateTime", "extract_last_incremental_update_time"),
                    ("extractLastUpdateTime", "extract_last_update_time"),
                    ("createdAt", "created_at"),
                    ("updatedAt", "updated_at")
                ]:
                    time_val = ds_data.get(time_field)
                    if time_val:
                        try:
                            setattr(ds, attr_name, datetime.fromisoformat(
                                time_val.replace("Z", "+00:00")
                            ))
                        except:
                            pass
                
                count += 1
                
                # åŒæ­¥è¡¨åˆ°æ•°æ®æºçš„å…³ç³»
                upstream_tables = ds_data.get("upstreamTables", [])
                for tbl in upstream_tables:
                    if not tbl or not tbl.get("id"):
                        continue
                    rel = self.session.execute(
                        select(table_to_datasource).where(
                            table_to_datasource.c.table_id == tbl["id"],
                            table_to_datasource.c.datasource_id == ds_data["id"]
                        )
                    ).first()
                    if not rel:
                        try:
                            self.session.execute(
                                table_to_datasource.insert().values(
                                    table_id=tbl["id"],
                                    datasource_id=ds_data["id"],
                                    relationship_type="upstream"
                                )
                            )
                        except:
                            pass
            
            self.session.commit()
            self._complete_sync_log(count)
            print(f"  âœ… åŒæ­¥ {count} ä¸ªæ•°æ®æº")
            return count
            
        except Exception as e:
            self.session.rollback()
            self._complete_sync_log(0, str(e))
            print(f"  âŒ åŒæ­¥å¤±è´¥: {e}")
            return 0
    
    def sync_workbooks(self) -> int:
        """åŒæ­¥å·¥ä½œç°¿å’Œè§†å›¾ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        print("\nğŸ“Š åŒæ­¥å·¥ä½œç°¿...")
        self._start_sync_log("workbooks")
        
        try:
            workbooks = self.client.fetch_workbooks()
            wb_count = 0
            view_count = 0
            
            for wb_data in workbooks:
                wb = self.session.query(Workbook).filter_by(id=wb_data["id"]).first()
                if not wb:
                    wb = Workbook(id=wb_data["id"])
                    self.session.add(wb)
                
                wb.name = wb_data.get("name", "")
                wb.luid = wb_data.get("luid")
                wb.description = wb_data.get("description")
                wb.uri = wb_data.get("uri")
                wb.project_name = wb_data.get("projectName", "")
                wb.contains_unsupported_custom_sql = wb_data.get("containsUnsupportedCustomSql", False)
                wb.has_active_warning = wb_data.get("hasActiveWarning", False)
                
                owner = wb_data.get("owner", {})
                if owner:
                    wb.owner = owner.get("username", "")
                    wb.owner_id = owner.get("id")
                
                # è§£ææ—¶é—´å­—æ®µ
                for time_field, attr_name in [("createdAt", "created_at"), ("updatedAt", "updated_at")]:
                    time_val = wb_data.get(time_field)
                    if time_val:
                        try:
                            setattr(wb, attr_name, datetime.fromisoformat(
                                time_val.replace("Z", "+00:00")
                            ))
                        except:
                            pass
                
                wb_count += 1
                
                # åŒæ­¥æ•°æ®æºåˆ°å·¥ä½œç°¿çš„å…³ç³»
                upstream_ds = wb_data.get("upstreamDatasources", [])
                for ds in upstream_ds:
                    if not ds or not ds.get("id"):
                        continue
                    rel = self.session.execute(
                        select(datasource_to_workbook).where(
                            datasource_to_workbook.c.datasource_id == ds["id"],
                            datasource_to_workbook.c.workbook_id == wb_data["id"]
                        )
                    ).first()
                    if not rel:
                        try:
                            self.session.execute(
                                datasource_to_workbook.insert().values(
                                    datasource_id=ds["id"],
                                    workbook_id=wb_data["id"]
                                )
                            )
                        except:
                            pass
                
                # åŒæ­¥è§†å›¾ (sheets + dashboards)
                all_views = wb_data.get("sheets", []) + wb_data.get("dashboards", [])
                for idx, sheet in enumerate(wb_data.get("sheets", [])):
                    if not sheet or not sheet.get("id"):
                        continue
                    view = self.session.query(View).filter_by(id=sheet["id"]).first()
                    if not view:
                        view = View(id=sheet["id"])
                        self.session.add(view)
                    
                    view.name = sheet.get("name", "")
                    view.luid = sheet.get("luid")
                    view.path = sheet.get("path")
                    view.index = sheet.get("index", idx)
                    view.view_type = "sheet"
                    view.workbook_id = wb_data["id"]
                    
                    # è§£ææ—¶é—´
                    for time_field, attr_name in [("createdAt", "created_at"), ("updatedAt", "updated_at")]:
                        time_val = sheet.get(time_field)
                        if time_val:
                            try:
                                setattr(view, attr_name, datetime.fromisoformat(
                                    time_val.replace("Z", "+00:00")
                                ))
                            except:
                                pass
                    
                    view_count += 1
                
                # åŒæ­¥ä»ªè¡¨æ¿ (dashboards)
                for idx, dashboard in enumerate(wb_data.get("dashboards", [])):
                    if not dashboard or not dashboard.get("id"):
                        continue
                    view = self.session.query(View).filter_by(id=dashboard["id"]).first()
                    if not view:
                        view = View(id=dashboard["id"])
                        self.session.add(view)
                    
                    view.name = dashboard.get("name", "")
                    view.luid = dashboard.get("luid")
                    view.path = dashboard.get("path")
                    view.index = dashboard.get("index", idx)
                    view.view_type = "dashboard"
                    view.workbook_id = wb_data["id"]
                    
                    # è§£ææ—¶é—´
                    for time_field, attr_name in [("createdAt", "created_at"), ("updatedAt", "updated_at")]:
                        time_val = dashboard.get(time_field)
                        if time_val:
                            try:
                                setattr(view, attr_name, datetime.fromisoformat(
                                    time_val.replace("Z", "+00:00")
                                ))
                            except:
                                pass
                    
                    view_count += 1
            
            self.session.commit()
            self._complete_sync_log(wb_count)
            print(f"  âœ… åŒæ­¥ {wb_count} ä¸ªå·¥ä½œç°¿, {view_count} ä¸ªè§†å›¾")
            return wb_count
            
        except Exception as e:
            self.session.rollback()
            self._complete_sync_log(0, str(e))
            print(f"  âŒ åŒæ­¥å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return 0
            return 0
    
    def sync_fields(self) -> int:
        """åŒæ­¥å­—æ®µ"""
        print("\nğŸ”¤ åŒæ­¥å­—æ®µ...")
        self._start_sync_log("fields")
        
        try:
            fields = self.client.fetch_fields()
            count = 0
            calc_count = 0
            
            for f_data in fields:
                if not f_data or not f_data.get("id"):
                    continue
                    
                field = self.session.query(Field).filter_by(id=f_data["id"]).first()
                if not field:
                    field = Field(id=f_data["id"])
                    self.session.add(field)
                
                field.name = f_data.get("name") or ""
                field.description = f_data.get("description") or ""
                field.data_type = f_data.get("dataType") or ""
                field.is_calculated = f_data.get("isCalculated") or False
                field.formula = f_data.get("formula") or ""
                field.role = f_data.get("role") or ""
                field.datasource_id = f_data.get("datasource_id")
                
                # å…³è”ä¸Šæ¸¸è¡¨
                upstream_cols = f_data.get("upstreamColumns") or []
                if upstream_cols and len(upstream_cols) > 0:
                    first_col = upstream_cols[0]
                    if first_col:
                        table_info = first_col.get("table")
                        if table_info:
                            field.table_id = table_info.get("id")
                
                count += 1
                
                # å¤„ç†è®¡ç®—å­—æ®µ
                if f_data.get("isCalculated"):
                    calc_field = self.session.query(CalculatedField).filter_by(
                        field_id=f_data["id"]
                    ).first()
                    if not calc_field:
                        calc_field = CalculatedField(field_id=f_data["id"])
                        self.session.add(calc_field)
                    
                    calc_field.name = f_data.get("name") or ""
                    calc_field.formula = f_data.get("formula") or ""
                    calc_count += 1
            
            self.session.commit()
            self._complete_sync_log(count)
            print(f"  âœ… åŒæ­¥ {count} ä¸ªå­—æ®µ (å…¶ä¸­ {calc_count} ä¸ªè®¡ç®—å­—æ®µ)")
            return count
            
        except Exception as e:
            self.session.rollback()
            self._complete_sync_log(0, str(e))
            print(f"  âŒ åŒæ­¥å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return 0
    
    def sync_calculated_fields(self) -> int:
        """åŒæ­¥è®¡ç®—å­—æ®µ"""
        print("\nğŸ“ åŒæ­¥è®¡ç®—å­—æ®µ...")
        self._start_sync_log("calculated_fields")
        
        try:
            calc_fields = self.client.fetch_calculated_fields()
            count = 0
            
            for cf_data in calc_fields:
                if not cf_data or not cf_data.get("id"):
                    continue
                
                # å…ˆç¡®ä¿ Field è®°å½•å­˜åœ¨
                field = self.session.query(Field).filter_by(id=cf_data["id"]).first()
                if not field:
                    field = Field(id=cf_data["id"])
                    self.session.add(field)
                
                field.name = cf_data.get("name") or ""
                field.description = cf_data.get("description") or ""
                field.data_type = cf_data.get("dataType") or ""
                field.is_calculated = True
                field.formula = cf_data.get("formula") or ""
                field.role = cf_data.get("role") or ""
                field.datasource_id = cf_data.get("datasource_id")
                
                # æ›´æ–°/åˆ›å»º CalculatedField è®°å½•
                calc_field = self.session.query(CalculatedField).filter_by(
                    field_id=cf_data["id"]
                ).first()
                if not calc_field:
                    calc_field = CalculatedField(field_id=cf_data["id"])
                    self.session.add(calc_field)
                
                calc_field.name = cf_data.get("name") or ""
                calc_field.formula = cf_data.get("formula") or ""
                count += 1
            
            self.session.commit()
            self._complete_sync_log(count)
            print(f"  âœ… åŒæ­¥ {count} ä¸ªè®¡ç®—å­—æ®µ")
            return count
            
        except Exception as e:
            self.session.rollback()
            self._complete_sync_log(0, str(e))
            print(f"  âŒ åŒæ­¥å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return 0
    
    def sync_field_to_view(self) -> int:
        """åŒæ­¥å­—æ®µåˆ°è§†å›¾çš„å…³è”å…³ç³»"""
        print("\nğŸ”— åŒæ­¥å­—æ®µâ†’è§†å›¾å…³è”...")
        self._start_sync_log("field_to_view")
        
        try:
            view_fields = self.client.fetch_views_with_fields()
            count = 0
            skipped = 0
            
            for vf in view_fields:
                field_id = vf.get("field_id")
                view_id = vf.get("view_id")
                
                if not field_id or not view_id:
                    skipped += 1
                    continue
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                existing = self.session.execute(
                    select(field_to_view).where(
                        field_to_view.c.field_id == field_id,
                        field_to_view.c.view_id == view_id
                    )
                ).first()
                
                if not existing:
                    try:
                        self.session.execute(
                            field_to_view.insert().values(
                                field_id=field_id,
                                view_id=view_id,
                                used_in_formula=False
                            )
                        )
                        count += 1
                    except Exception as e:
                        # å¿½ç•¥å¤–é”®çº¦æŸé”™è¯¯ï¼ˆå­—æ®µæˆ–è§†å›¾ä¸å­˜åœ¨ï¼‰
                        skipped += 1
                        continue
            
            self.session.commit()
            self._complete_sync_log(count)
            print(f"  âœ… åŒæ­¥ {count} ä¸ªå­—æ®µâ†’è§†å›¾å…³è” (è·³è¿‡ {skipped} ä¸ª)")
            return count
            
        except Exception as e:
            self.session.rollback()
            self._complete_sync_log(0, str(e))
            print(f"  âŒ åŒæ­¥å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return 0
    
    def sync_users(self) -> int:
        """åŒæ­¥ Tableau ç”¨æˆ·"""
        print("\nğŸ‘¥ åŒæ­¥ç”¨æˆ·...")
        self._start_sync_log("users")
        
        try:
            users = self.client.fetch_users()
            count = 0
            
            for u_data in users:
                if not u_data or not u_data.get("id"):
                    continue
                    
                user = self.session.query(TableauUser).filter_by(id=u_data["id"]).first()
                if not user:
                    user = TableauUser(id=u_data["id"])
                    self.session.add(user)
                
                user.luid = u_data.get("luid")
                user.name = u_data.get("username") or u_data.get("name") or ""
                user.display_name = u_data.get("name")
                user.email = u_data.get("email")
                user.domain = u_data.get("domain")
                user.site_role = u_data.get("siteRole")
                count += 1
            
            self.session.commit()
            self._complete_sync_log(count)
            print(f"  âœ… åŒæ­¥ {count} ä¸ªç”¨æˆ·")
            return count
            
        except Exception as e:
            self.session.rollback()
            self._complete_sync_log(0, str(e))
            print(f"  âŒ åŒæ­¥å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return 0
    
    def sync_projects(self) -> int:
        """åŒæ­¥ Tableau é¡¹ç›®"""
        print("\nğŸ“ åŒæ­¥é¡¹ç›®...")
        self._start_sync_log("projects")
        
        try:
            projects = self.client.fetch_projects()
            count = 0
            
            for p_data in projects:
                if not p_data or not p_data.get("name"):
                    continue
                
                project_id = p_data.get("id")
                
                project = self.session.query(Project).filter_by(id=project_id).first()
                if not project:
                    project = Project(id=project_id)
                    self.session.add(project)
                
                project.name = p_data.get("name") or ""
                project.vizportal_url_id = p_data.get("vizportalUrlId")
                count += 1
            
            self.session.commit()
            self._complete_sync_log(count)
            print(f"  âœ… åŒæ­¥ {count} ä¸ªé¡¹ç›®")
            return count
            
        except Exception as e:
            self.session.rollback()
            self._complete_sync_log(0, str(e))
            print(f"  âŒ åŒæ­¥å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return 0

    def sync_lineage(self) -> int:
        """åŒæ­¥æŒ‡æ ‡ä¸è¡€ç¼˜å…³ç³» (DBæŒä¹…åŒ–)"""
        print("\nğŸ•¸ï¸ åŒæ­¥è¡€ç¼˜ä¸æŒ‡æ ‡å…³ç³»...")
        count = 0
        
        try:
            # 1. æ¸…ç†ç°æœ‰ä¾èµ–å…³ç³» (å…¨é‡åŒæ­¥ç­–ç•¥)
            self.session.query(FieldDependency).delete()
            self.session.query(Metric).delete() # é‡æ–°æ„å»ºæŒ‡æ ‡è¡¨
            self.session.commit()
            
            # 2. è·å–æ‰€æœ‰è®¡ç®—å­—æ®µ
            calc_fields = self.session.query(CalculatedField, Field).join(
                Field, CalculatedField.field_id == Field.id
            ).all()
            
            # æ„å»ºå­—æ®µç´¢å¼• (Name -> ID lookup cache)
            all_fields = self.session.query(Field).all()
            field_map = {} # (datasource_id, name) -> field_id
            global_field_map = {} # name -> field_id (fallback)
            
            for f in all_fields:
                key = (f.datasource_id, f.name)
                field_map[key] = f.id
                global_field_map[f.name] = f.id
            
            for calc, field in calc_fields:
                formula = calc.formula
                if not formula:
                    continue
                    
                # A. è¯†åˆ« Metric
                # è§„åˆ™: è®¡ç®—å­—æ®µ ä¸” Role=Measure
                if field.role == 'measure':
                    metric = Metric(
                        id=field.id, # å¤ç”¨ Field ID
                        name=field.name,
                        description=field.description,
                        formula=formula,
                        metric_type='Calculated',
                        owner=field.datasource.owner if field.datasource else None
                    )
                    self.session.merge(metric)
                
                # B. è§£æä¾èµ– (åç«¯æŒä¹…åŒ–)
                refs = re.findall(r'\[(.*?)\]', formula)
                unique_refs = set(refs)
                
                for ref_name in unique_refs:
                    dep_id = None
                    
                    # 1. å°è¯•åŒæ•°æ®æºåŒ¹é…
                    if field.datasource_id:
                        dep_id = field_map.get((field.datasource_id, ref_name))
                    
                    # 2. å°è¯•å…¨å±€åŒ¹é…
                    if not dep_id:
                        dep_id = global_field_map.get(ref_name)
                    
                    # 3. åˆ›å»ºä¾èµ–è®°å½•
                    dependency = FieldDependency(
                        source_field_id=field.id,
                        dependency_field_id=dep_id, 
                        dependency_name=ref_name,
                        dependency_type='formula'
                    )
                    self.session.add(dependency)
                    count += 1
            
            self.session.commit()
            print(f"  âœ… åŒæ­¥ {count} æ¡ä¾èµ–å…³ç³»")
            return count
            
        except Exception as e:
            self.session.rollback()
            print(f"  âŒ è¡€ç¼˜åŒæ­¥å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return 0
    
    def sync_all(self):
        """å…¨é‡åŒæ­¥æ‰€æœ‰å®ä½“"""
        print("=" * 60)
        print("ğŸš€ å¼€å§‹å…¨é‡åŒæ­¥ Tableau Metadata")
        print("=" * 60)
        
        start_time = datetime.now()
        
        # æŒ‰ä¾èµ–é¡ºåºåŒæ­¥
        user_count = self.sync_users()  # å…ˆåŒæ­¥ç”¨æˆ·
        project_count = self.sync_projects()  # åŒæ­¥é¡¹ç›®
        db_count = self.sync_databases()
        table_count = self.sync_tables()
        ds_count = self.sync_datasources()
        wb_count = self.sync_workbooks()
        field_count = self.sync_fields()
        calc_count = self.sync_calculated_fields()
        calc_count = self.sync_calculated_fields()
        ftv_count = self.sync_field_to_view()
        lineage_count = self.sync_lineage()
        
        duration = (datetime.now() - start_time).total_seconds()
        
        print("\n" + "=" * 60)
        print("ğŸ“ˆ åŒæ­¥å®Œæˆç»Ÿè®¡")
        print("=" * 60)
        print(f"  ç”¨æˆ·:   {user_count}")
        print(f"  é¡¹ç›®:   {project_count}")
        print(f"  æ•°æ®åº“: {db_count}")
        print(f"  æ•°æ®è¡¨: {table_count}")
        print(f"  æ•°æ®æº: {ds_count}")
        print(f"  å·¥ä½œç°¿: {wb_count}")
        print(f"  è¡€ç¼˜:   {lineage_count}")
        print(f"  å­—æ®µ:   {field_count}")
        print(f"  è®¡ç®—å­—æ®µ: {calc_count}")
        print(f"  å­—æ®µâ†’è§†å›¾: {ftv_count}")
        print(f"  è€—æ—¶: {duration:.2f} ç§’")
        print("=" * 60)
        
        # åŒæ­¥è§†å›¾ä½¿ç”¨ç»Ÿè®¡ï¼ˆé€šè¿‡ REST APIï¼‰
        self.sync_views_usage()
        
        # æœ€åï¼šè®¡ç®—é¢„å­˜ç»Ÿè®¡å­—æ®µ
        self.calculate_stats()
    
    def sync_views_usage(self) -> int:
        """åŒæ­¥è§†å›¾ä½¿ç”¨ç»Ÿè®¡ï¼ˆé€šè¿‡ REST APIï¼‰å¹¶è®°å½•å†å²å¿«ç…§"""
        print("\nğŸ“Š åŒæ­¥è§†å›¾ä½¿ç”¨ç»Ÿè®¡ (REST API)...")
        
        try:
            usage_map = self.client.fetch_views_usage()
            
            if not usage_map:
                print("  âš ï¸ æœªè·å–åˆ°è§†å›¾ä½¿ç”¨ç»Ÿè®¡")
                return 0
            
            updated = 0
            history_count = 0
            views = self.session.query(View).all()
            
            for view in views:
                # REST API è¿”å›çš„æ˜¯ luidï¼Œéœ€è¦åŒ¹é…
                if view.luid and view.luid in usage_map:
                    new_count = usage_map[view.luid]
                    
                    # åªæœ‰å½“è®¿é—®æ¬¡æ•°å‘ç”Ÿå˜åŒ–æ—¶æ‰è®°å½•å†å²
                    if view.total_view_count != new_count:
                        # è®°å½•å†å²å¿«ç…§
                        from backend.models import ViewUsageHistory
                        history = ViewUsageHistory(
                            view_id=view.id,
                            view_luid=view.luid,
                            total_view_count=new_count
                        )
                        self.session.add(history)
                        history_count += 1
                    
                    view.total_view_count = new_count
                    updated += 1
            
            self.session.commit()
            print(f"  âœ… æ›´æ–° {updated} ä¸ªè§†å›¾çš„ä½¿ç”¨ç»Ÿè®¡, è®°å½• {history_count} æ¡å†å²")
            return updated
            
        except Exception as e:
            print(f"  âŒ åŒæ­¥è§†å›¾ä½¿ç”¨ç»Ÿè®¡å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return 0
    
    def calculate_stats(self):
        """è®¡ç®—å¹¶æ›´æ–°é¢„å­˜ç»Ÿè®¡å­—æ®µï¼ˆåŒæ­¥ç»“æŸåè°ƒç”¨ï¼‰"""
        print("\nğŸ“Š è®¡ç®—é¢„å­˜ç»Ÿè®¡å­—æ®µ...")
        
        try:
            # ========== Workbook ç»Ÿè®¡ ==========
            workbooks = self.session.query(Workbook).all()
            for wb in workbooks:
                wb.view_count = len(wb.views) if wb.views else 0
                wb.datasource_count = len(wb.datasources) if wb.datasources else 0
                
                # ç»Ÿè®¡å­—æ®µå’ŒæŒ‡æ ‡ï¼ˆéœ€æŸ¥è¯¢è§†å›¾ä¸­çš„å­—æ®µï¼‰
                field_ids = set()
                metric_ids = set()
                for v in (wb.views or []):
                    for f in (v.fields or []):
                        if f.is_calculated:
                            metric_ids.add(f.id)
                        else:
                            field_ids.add(f.id)
                wb.field_count = len(field_ids)
                wb.metric_count = len(metric_ids)
            
            # ========== Datasource ç»Ÿè®¡ ==========
            datasources = self.session.query(Datasource).all()
            for ds in datasources:
                ds.table_count = len(ds.tables) if ds.tables else 0
                ds.workbook_count = len(ds.workbooks) if ds.workbooks else 0
                
                field_count = 0
                metric_count = 0
                for f in (ds.fields or []):
                    if f.is_calculated:
                        metric_count += 1
                    else:
                        field_count += 1
                ds.field_count = field_count
                ds.metric_count = metric_count
            
            # ========== Field & CalculatedField æ·±åº¦ç»Ÿè®¡ (æŒ‡æ ‡é¢„è®¡ç®—ä¼˜åŒ–) ==========
            print("  - è®¡ç®—å­—æ®µå’ŒæŒ‡æ ‡æ·±åº¦ç»Ÿè®¡...")
            
            # 1. è®¡ç®—å­—æ®µå…¬å¼å“ˆå¸ŒåŠæŸ¥é‡
            calc_fields = self.session.query(CalculatedField).all()
            formula_map = defaultdict(list)
            for cf in calc_fields:
                if cf.formula:
                    # æ ‡å‡†åŒ–å…¬å¼å¹¶è®¡ç®—å“ˆå¸Œ
                    formula_clean = cf.formula.strip()
                    h = hashlib.md5(formula_clean.encode('utf-8')).hexdigest()
                    cf.formula_hash = h
                    formula_map[h].append(cf)
            
            # æ›´æ–°æŸ¥é‡ä¿¡æ¯
            for h, cfs in formula_map.items():
                is_duplicate = len(cfs) > 1
                for cf in cfs:
                    cf.has_duplicates = is_duplicate
                    cf.duplicate_count = len(cfs) - 1
            
            # 2. ç»Ÿè®¡å­—æ®µè¢«è§†å›¾å¼•ç”¨çš„æ¬¡æ•° (usage_count)
            print("  - ä½¿ç”¨ SQL æ‰¹é‡æ›´æ–°è§†å›¾å¼•ç”¨æ¬¡æ•°...")
            self.session.execute(text("""
                UPDATE fields SET usage_count = (
                    SELECT COUNT(*) FROM field_to_view 
                    WHERE field_to_view.field_id = fields.id
                )
            """))
            
            # 3. ç»Ÿè®¡å­—æ®µè¢«æŒ‡æ ‡å¼•ç”¨çš„æ¬¡æ•° (metric_usage_count)
            print("  - ä½¿ç”¨ SQL æ‰¹é‡æ›´æ–°æŒ‡æ ‡å¼•ç”¨æ¬¡æ•°...")
            self.session.execute(text("""
                UPDATE fields SET metric_usage_count = (
                    SELECT COUNT(*) FROM field_dependencies 
                    WHERE field_dependencies.dependency_name = fields.name
                )
            """))
            
            # 4. ç»Ÿè®¡æŒ‡æ ‡ä¾èµ–æ•° (dependency_count)
            print("  - ä½¿ç”¨ SQL æ‰¹é‡æ›´æ–°æŒ‡æ ‡ä¾èµ–æ•°...")
            self.session.execute(text("""
                UPDATE calculated_fields SET dependency_count = (
                    SELECT COUNT(*) FROM field_dependencies 
                    WHERE field_dependencies.source_field_id = calculated_fields.field_id
                )
            """))

            # 5. ç»Ÿè®¡æŒ‡æ ‡å¼•ç”¨æ•° (reference_count)
            print("  - ä½¿ç”¨ SQL æ‰¹é‡æ›´æ–°æŒ‡æ ‡å¼•ç”¨æ•°...")
            self.session.execute(text("""
                UPDATE calculated_fields SET reference_count = (
                    SELECT COUNT(*) FROM field_dependencies 
                    WHERE field_dependencies.dependency_field_id = calculated_fields.field_id
                )
            """))

            self.session.commit()
            print(f"  âœ… å·²æ›´æ–° {len(workbooks)} ä¸ªå·¥ä½œç°¿, {len(datasources)} ä¸ªæ•°æ®æº, {len(calc_fields)} ä¸ªè®¡ç®—å­—æ®µçš„ç»Ÿè®¡å­—æ®µ")
            
        except Exception as e:
            self.session.rollback()
            print(f"  âŒ ç»Ÿè®¡è®¡ç®—å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def close(self):
        """å…³é—­ä¼šè¯"""
        self.session.close()


def main():
    """ä¸»å‡½æ•° - æ‰§è¡ŒåŒæ­¥"""
    print("\n" + "=" * 60)
    print("Tableau Metadata åŒæ­¥å·¥å…·")
    print("=" * 60)
    
    # é…ç½®
    BASE_URL = "http://tbi.juneyaoair.com"
    USERNAME = "huangguanru"
    PASSWORD = "Admin123"
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    client = TableauMetadataClient(BASE_URL, USERNAME, PASSWORD)
    
    # ç™»å½•
    if not client.sign_in():
        print("æ— æ³•ç™»å½•ï¼Œé€€å‡º")
        return
    
    try:
        # åˆ›å»ºåŒæ­¥ç®¡ç†å™¨
        sync = MetadataSync(client)
        
        # æ‰§è¡Œå…¨é‡åŒæ­¥
        sync.sync_all()
        
        sync.close()
        
    finally:
        # ç™»å‡º
        client.sign_out()


if __name__ == "__main__":
    main()
