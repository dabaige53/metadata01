# 字段去重穿透继承问题分析

## 问题现象

同一数据源 `销售航段` 中的字段 `BOARDED_FLAG` 有 **18 条记录**：
- 1 条有 `upstream_column_id`（来自发布数据源的同步）
- 17 条无 `upstream_column_id`（来自各个工作簿引用）

使用三层去重策略 V4 时，产生了 **2 个 unique key**（应该是 1 个）。

## 根因分析

V4 策略按"有列用列，无列用数据源+名称"分层去重：
```
有 upstream_column_id → col::29f59c4d...  (1条)
无 upstream_column_id → ds::41057d26...::BOARDED_FLAG  (17条)
```

但这 18 条其实是**同一个物理字段**！只是同步来源不同导致只有 1 条有物理列信息。

## 影响范围

- 原始字段：**1,858 组**同数据源同名字段被错误分成多个 unique
- 预计多产生 ~2,800 个冗余 unique 记录

## 解决方案

**V5 策略：同名继承**

```python
# 第一遍：构建继承映射
canonical_map = {}  # (datasource_id, name) -> upstream_column_id
for field in fields:
    if field.upstream_column_id and field.datasource_id:
        key = (field.datasource_id, field.name)
        canonical_map[key] = field.upstream_column_id

# 第二遍：去重时继承
def get_dedup_key(field):
    inherited = canonical_map.get((field.datasource_id, field.name))
    if field.upstream_column_id:
        return f"col::{field.upstream_column_id}"
    elif inherited:
        return f"col::{inherited}"  # 继承同名的列ID
    elif field.table_id:
        return f"table::{field.table_id}::{field.name}"
    elif field.datasource_id:
        return f"ds::{field.datasource_id}::{field.name}"
    else:
        return f"orphan::{field.id}"
```

## 实施状态

- [x] 问题分析
- [ ] V5 迁移脚本实现
- [ ] 验证无残留重复
