"""
Tableau Metadata API æ•°æ®åŒæ­¥æ¨¡å—
ä» Tableau Server æŠ“å–å…ƒæ•°æ®å¹¶å­˜å…¥æœ¬åœ°æ•°æ®åº“
"""
import os
import sys
import json
import requests
from datetime import datetime
from typing import Optional, List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from app.config import Config
from app.models import (
    get_engine, get_session,
    Database, Table, Field, Datasource, Workbook, View,
    TableToDatasource, DatasourceToWorkbook, CalculatedField, SyncLog
)


class TableauMetadataClient:
    """Tableau Metadata API å®¢æˆ·ç«¯"""
    
    def __init__(self, base_url: str, username: str, password: str):
        self.base_url = base_url.rstrip('/')
        self.username = username
        self.password = password
        self.auth_token: Optional[str] = None
        self.site_id: Optional[str] = None
        self.api_version = "3.10"
    
    def sign_in(self) -> bool:
        """ç™»å½•è·å–è®¤è¯ token"""
        signin_url = f"{self.base_url}/api/{self.api_version}/auth/signin"
        
        payload = {
            "credentials": {
                "name": self.username,
                "password": self.password,
                "site": {"contentUrl": ""}
            }
        }
        
        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json"
        }
        
        try:
            response = requests.post(signin_url, headers=headers, json=payload, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                credentials = data.get("credentials", {})
                self.auth_token = credentials.get("token")
                self.site_id = credentials.get("site", {}).get("id")
                print(f"âœ… ç™»å½•æˆåŠŸ (Token: {self.auth_token[:20]}...)")
                return True
            else:
                print(f"âŒ ç™»å½•å¤±è´¥: {response.text}")
                return False
        except Exception as e:
            print(f"âŒ ç™»å½•å¼‚å¸¸: {e}")
            return False
    
    def sign_out(self):
        """ç™»å‡ºé‡Šæ”¾ token"""
        if not self.auth_token:
            return
        
        signout_url = f"{self.base_url}/api/{self.api_version}/auth/signout"
        headers = {"X-Tableau-Auth": self.auth_token}
        
        try:
            response = requests.post(signout_url, headers=headers, timeout=30)
            if response.status_code == 204:
                print("âœ… å·²ç™»å‡º")
        except Exception as e:
            print(f"ç™»å‡ºå¼‚å¸¸: {e}")
        finally:
            self.auth_token = None
    
    def execute_query(self, query: str) -> Dict[str, Any]:
        """æ‰§è¡Œ GraphQL æŸ¥è¯¢"""
        if not self.auth_token:
            raise RuntimeError("æœªç™»å½•ï¼Œè¯·å…ˆè°ƒç”¨ sign_in()")
        
        url = f"{self.base_url}/api/metadata/graphql"
        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json",
            "X-Tableau-Auth": self.auth_token
        }
        
        response = requests.post(url, headers=headers, json={"query": query}, timeout=60)
        
        if response.status_code == 200:
            return response.json()
        else:
            raise RuntimeError(f"GraphQL æŸ¥è¯¢å¤±è´¥: {response.status_code} - {response.text}")
    
    def fetch_databases(self) -> List[Dict]:
        """è·å–æ‰€æœ‰æ•°æ®åº“"""
        query = """
        {
            databases {
                id
                name
                connectionType
            }
        }
        """
        result = self.execute_query(query)
        return result.get("data", {}).get("databases", [])
    
    def fetch_tables(self) -> List[Dict]:
        """è·å–æ‰€æœ‰æ•°æ®è¡¨"""
        query = """
        {
            databaseTables {
                id
                name
                schema
                fullName
                database {
                    id
                    name
                    connectionType
                }
            }
        }
        """
        result = self.execute_query(query)
        return result.get("data", {}).get("databaseTables", [])
    
    def fetch_datasources(self) -> List[Dict]:
        """è·å–æ‰€æœ‰å·²å‘å¸ƒæ•°æ®æº"""
        query = """
        {
            publishedDatasources {
                id
                name
                projectName
                hasExtracts
                extractLastRefreshTime
                owner {
                    username
                }
                upstreamTables {
                    id
                    name
                }
            }
        }
        """
        result = self.execute_query(query)
        return result.get("data", {}).get("publishedDatasources", [])
    
    def fetch_workbooks(self) -> List[Dict]:
        """è·å–æ‰€æœ‰å·¥ä½œç°¿"""
        query = """
        {
            workbooks {
                id
                name
                projectName
                createdAt
                updatedAt
                owner {
                    username
                }
                upstreamDatasources {
                    id
                    name
                }
                sheets {
                    id
                    name
                }
            }
        }
        """
        result = self.execute_query(query)
        return result.get("data", {}).get("workbooks", [])
    
    def fetch_fields(self) -> List[Dict]:
        """è·å–æ‰€æœ‰å­—æ®µï¼ˆé€šè¿‡æ•°æ®æºï¼‰"""
        query = """
        {
            publishedDatasources {
                id
                name
                fields {
                    id
                    name
                    description
                }
            }
        }
        """
        result = self.execute_query(query)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        if "errors" in result:
            print(f"  âš ï¸ GraphQL é”™è¯¯: {result['errors']}")
            return []
        
        data = result.get("data")
        if data is None:
            print(f"  âš ï¸ æœªè·å–åˆ°æ•°æ®: {result}")
            return []
            
        datasources = data.get("publishedDatasources") or []
        
        # å±•å¹³å­—æ®µåˆ—è¡¨
        all_fields = []
        for ds in datasources:
            if not ds:
                continue
            ds_id = ds.get("id")
            ds_name = ds.get("name")
            fields = ds.get("fields") or []
            for field in fields:
                if field and field.get("id"):
                    field["datasource_id"] = ds_id
                    field["datasource_name"] = ds_name
                    all_fields.append(field)
        
        return all_fields
    
    def fetch_calculated_fields(self) -> List[Dict]:
        """è·å–æ‰€æœ‰è®¡ç®—å­—æ®µ"""
        query = """
        {
            calculatedFields {
                id
                name
                description
                formula
                dataType
                role
                datasource {
                    id
                    name
                }
            }
        }
        """
        result = self.execute_query(query)
        
        # æ£€æŸ¥é”™è¯¯
        if "errors" in result:
            print(f"  âš ï¸ GraphQL é”™è¯¯: {result['errors']}")
            return []
        
        data = result.get("data")
        if data is None:
            return []
        
        calc_fields = data.get("calculatedFields") or []
        
        # å¤„ç†æ•°æ®ï¼Œæ·»åŠ  datasource_id
        for cf in calc_fields:
            if cf and cf.get("datasource"):
                cf["datasource_id"] = cf["datasource"].get("id")
        
        return calc_fields


class MetadataSync:
    """å…ƒæ•°æ®åŒæ­¥ç®¡ç†å™¨"""
    
    def __init__(self, client: TableauMetadataClient, db_path: str = None):
        self.client = client
        self.db_path = db_path or Config.DATABASE_PATH
        self.engine = get_engine(self.db_path)
        self.session = get_session(self.engine)
        self.sync_log: Optional[SyncLog] = None
    
    def _start_sync_log(self, sync_type: str):
        """å¼€å§‹åŒæ­¥æ—¥å¿—"""
        self.sync_log = SyncLog(
            sync_type=sync_type,
            status="running",
            started_at=datetime.now(),
            records_synced=0
        )
        self.session.add(self.sync_log)
        self.session.commit()
    
    def _complete_sync_log(self, records: int, error: str = None):
        """å®ŒæˆåŒæ­¥æ—¥å¿—"""
        if self.sync_log:
            self.sync_log.status = "error" if error else "completed"
            self.sync_log.completed_at = datetime.now()
            self.sync_log.records_synced = records
            self.sync_log.error_message = error
            self.session.commit()
    
    def sync_databases(self) -> int:
        """åŒæ­¥æ•°æ®åº“"""
        print("\nğŸ“¦ åŒæ­¥æ•°æ®åº“...")
        self._start_sync_log("databases")
        
        try:
            databases = self.client.fetch_databases()
            count = 0
            
            for db_data in databases:
                db = self.session.query(Database).filter_by(id=db_data["id"]).first()
                if not db:
                    db = Database(id=db_data["id"])
                    self.session.add(db)
                
                db.name = db_data.get("name", "")
                db.connection_type = db_data.get("connectionType", "")
                db.updated_at = datetime.now()
                count += 1
            
            self.session.commit()
            self._complete_sync_log(count)
            print(f"  âœ… åŒæ­¥ {count} ä¸ªæ•°æ®åº“")
            return count
            
        except Exception as e:
            self.session.rollback()
            self._complete_sync_log(0, str(e))
            print(f"  âŒ åŒæ­¥å¤±è´¥: {e}")
            return 0
    
    def sync_tables(self) -> int:
        """åŒæ­¥æ•°æ®è¡¨"""
        print("\nğŸ“‹ åŒæ­¥æ•°æ®è¡¨...")
        self._start_sync_log("tables")
        
        try:
            tables = self.client.fetch_tables()
            count = 0
            
            for t_data in tables:
                table = self.session.query(Table).filter_by(id=t_data["id"]).first()
                if not table:
                    table = Table(id=t_data["id"])
                    self.session.add(table)
                
                table.name = t_data.get("name", "")
                table.schema = t_data.get("schema", "")
                table.full_name = t_data.get("fullName", "")
                
                # å…³è”æ•°æ®åº“
                db_info = t_data.get("database", {})
                if db_info:
                    table.database_id = db_info.get("id")
                    table.connection_type = db_info.get("connectionType", "")
                
                table.updated_at = datetime.now()
                count += 1
            
            self.session.commit()
            self._complete_sync_log(count)
            print(f"  âœ… åŒæ­¥ {count} ä¸ªæ•°æ®è¡¨")
            return count
            
        except Exception as e:
            self.session.rollback()
            self._complete_sync_log(0, str(e))
            print(f"  âŒ åŒæ­¥å¤±è´¥: {e}")
            return 0
    
    def sync_datasources(self) -> int:
        """åŒæ­¥æ•°æ®æº"""
        print("\nğŸ”— åŒæ­¥æ•°æ®æº...")
        self._start_sync_log("datasources")
        
        try:
            datasources = self.client.fetch_datasources()
            count = 0
            
            for ds_data in datasources:
                ds = self.session.query(Datasource).filter_by(id=ds_data["id"]).first()
                if not ds:
                    ds = Datasource(id=ds_data["id"])
                    self.session.add(ds)
                
                ds.name = ds_data.get("name", "")
                ds.project_name = ds_data.get("projectName", "")
                ds.has_extract = ds_data.get("hasExtracts", False)
                
                owner = ds_data.get("owner", {})
                if owner:
                    ds.owner = owner.get("username", "")
                
                # è§£æåˆ·æ–°æ—¶é—´
                refresh_time = ds_data.get("extractLastRefreshTime")
                if refresh_time:
                    try:
                        ds.extract_last_refresh_time = datetime.fromisoformat(
                            refresh_time.replace("Z", "+00:00")
                        )
                    except:
                        pass
                
                ds.updated_at = datetime.now()
                count += 1
                
                # åŒæ­¥è¡¨åˆ°æ•°æ®æºçš„å…³ç³»
                upstream_tables = ds_data.get("upstreamTables", [])
                for tbl in upstream_tables:
                    rel = self.session.query(TableToDatasource).filter_by(
                        table_id=tbl["id"],
                        datasource_id=ds_data["id"]
                    ).first()
                    if not rel:
                        rel = TableToDatasource(
                            table_id=tbl["id"],
                            datasource_id=ds_data["id"],
                            relationship_type="upstream"
                        )
                        self.session.add(rel)
            
            self.session.commit()
            self._complete_sync_log(count)
            print(f"  âœ… åŒæ­¥ {count} ä¸ªæ•°æ®æº")
            return count
            
        except Exception as e:
            self.session.rollback()
            self._complete_sync_log(0, str(e))
            print(f"  âŒ åŒæ­¥å¤±è´¥: {e}")
            return 0
    
    def sync_workbooks(self) -> int:
        """åŒæ­¥å·¥ä½œç°¿å’Œè§†å›¾"""
        print("\nğŸ“Š åŒæ­¥å·¥ä½œç°¿...")
        self._start_sync_log("workbooks")
        
        try:
            workbooks = self.client.fetch_workbooks()
            wb_count = 0
            view_count = 0
            
            for wb_data in workbooks:
                wb = self.session.query(Workbook).filter_by(id=wb_data["id"]).first()
                if not wb:
                    wb = Workbook(id=wb_data["id"])
                    self.session.add(wb)
                
                wb.name = wb_data.get("name", "")
                wb.project_name = wb_data.get("projectName", "")
                
                owner = wb_data.get("owner", {})
                if owner:
                    wb.owner = owner.get("username", "")
                
                # è§£ææ—¶é—´
                created_at = wb_data.get("createdAt")
                if created_at:
                    try:
                        wb.created_at = datetime.fromisoformat(created_at.replace("Z", "+00:00"))
                    except:
                        pass
                
                updated_at = wb_data.get("updatedAt")
                if updated_at:
                    try:
                        wb.updated_at = datetime.fromisoformat(updated_at.replace("Z", "+00:00"))
                    except:
                        wb.updated_at = datetime.now()
                
                wb_count += 1
                
                # åŒæ­¥æ•°æ®æºåˆ°å·¥ä½œç°¿çš„å…³ç³»
                upstream_ds = wb_data.get("upstreamDatasources", [])
                for ds in upstream_ds:
                    rel = self.session.query(DatasourceToWorkbook).filter_by(
                        datasource_id=ds["id"],
                        workbook_id=wb_data["id"]
                    ).first()
                    if not rel:
                        rel = DatasourceToWorkbook(
                            datasource_id=ds["id"],
                            workbook_id=wb_data["id"]
                        )
                        self.session.add(rel)
                
                # åŒæ­¥è§†å›¾ (sheets)
                sheets = wb_data.get("sheets", [])
                for sheet in sheets:
                    view = self.session.query(View).filter_by(id=sheet["id"]).first()
                    if not view:
                        view = View(id=sheet["id"])
                        self.session.add(view)
                    
                    view.name = sheet.get("name", "")
                    view.workbook_id = wb_data["id"]
                    view.updated_at = datetime.now()
                    view_count += 1
            
            self.session.commit()
            self._complete_sync_log(wb_count)
            print(f"  âœ… åŒæ­¥ {wb_count} ä¸ªå·¥ä½œç°¿, {view_count} ä¸ªè§†å›¾")
            return wb_count
            
        except Exception as e:
            self.session.rollback()
            self._complete_sync_log(0, str(e))
            print(f"  âŒ åŒæ­¥å¤±è´¥: {e}")
            return 0
    
    def sync_fields(self) -> int:
        """åŒæ­¥å­—æ®µ"""
        print("\nğŸ”¤ åŒæ­¥å­—æ®µ...")
        self._start_sync_log("fields")
        
        try:
            fields = self.client.fetch_fields()
            count = 0
            calc_count = 0
            
            for f_data in fields:
                if not f_data or not f_data.get("id"):
                    continue
                    
                field = self.session.query(Field).filter_by(id=f_data["id"]).first()
                if not field:
                    field = Field(id=f_data["id"])
                    self.session.add(field)
                
                field.name = f_data.get("name") or ""
                field.description = f_data.get("description") or ""
                field.data_type = f_data.get("dataType") or ""
                field.is_calculated = f_data.get("isCalculated") or False
                field.formula = f_data.get("formula") or ""
                field.role = f_data.get("role") or ""
                field.datasource_id = f_data.get("datasource_id")
                
                # å…³è”ä¸Šæ¸¸è¡¨
                upstream_cols = f_data.get("upstreamColumns") or []
                if upstream_cols and len(upstream_cols) > 0:
                    first_col = upstream_cols[0]
                    if first_col:
                        table_info = first_col.get("table")
                        if table_info:
                            field.table_id = table_info.get("id")
                
                field.updated_at = datetime.now()
                count += 1
                
                # å¤„ç†è®¡ç®—å­—æ®µ
                if f_data.get("isCalculated"):
                    calc_field = self.session.query(CalculatedField).filter_by(
                        field_id=f_data["id"]
                    ).first()
                    if not calc_field:
                        calc_field = CalculatedField(field_id=f_data["id"])
                        self.session.add(calc_field)
                    
                    calc_field.name = f_data.get("name") or ""
                    calc_field.formula = f_data.get("formula") or ""
                    calc_count += 1
            
            self.session.commit()
            self._complete_sync_log(count)
            print(f"  âœ… åŒæ­¥ {count} ä¸ªå­—æ®µ (å…¶ä¸­ {calc_count} ä¸ªè®¡ç®—å­—æ®µ)")
            return count
            
        except Exception as e:
            self.session.rollback()
            self._complete_sync_log(0, str(e))
            print(f"  âŒ åŒæ­¥å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return 0
    
    def sync_calculated_fields(self) -> int:
        """åŒæ­¥è®¡ç®—å­—æ®µ"""
        print("\nğŸ“ åŒæ­¥è®¡ç®—å­—æ®µ...")
        self._start_sync_log("calculated_fields")
        
        try:
            calc_fields = self.client.fetch_calculated_fields()
            count = 0
            
            for cf_data in calc_fields:
                if not cf_data or not cf_data.get("id"):
                    continue
                
                # å…ˆç¡®ä¿ Field è®°å½•å­˜åœ¨
                field = self.session.query(Field).filter_by(id=cf_data["id"]).first()
                if not field:
                    field = Field(id=cf_data["id"])
                    self.session.add(field)
                
                field.name = cf_data.get("name") or ""
                field.description = cf_data.get("description") or ""
                field.data_type = cf_data.get("dataType") or ""
                field.is_calculated = True
                field.formula = cf_data.get("formula") or ""
                field.role = cf_data.get("role") or ""
                field.datasource_id = cf_data.get("datasource_id")
                field.updated_at = datetime.now()
                
                # æ›´æ–°/åˆ›å»º CalculatedField è®°å½•
                calc_field = self.session.query(CalculatedField).filter_by(
                    field_id=cf_data["id"]
                ).first()
                if not calc_field:
                    calc_field = CalculatedField(field_id=cf_data["id"])
                    self.session.add(calc_field)
                
                calc_field.name = cf_data.get("name") or ""
                calc_field.formula = cf_data.get("formula") or ""
                count += 1
            
            self.session.commit()
            self._complete_sync_log(count)
            print(f"  âœ… åŒæ­¥ {count} ä¸ªè®¡ç®—å­—æ®µ")
            return count
            
        except Exception as e:
            self.session.rollback()
            self._complete_sync_log(0, str(e))
            print(f"  âŒ åŒæ­¥å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return 0
    
    def sync_all(self):
        """å…¨é‡åŒæ­¥æ‰€æœ‰å®ä½“"""
        print("=" * 60)
        print("ğŸš€ å¼€å§‹å…¨é‡åŒæ­¥ Tableau Metadata")
        print("=" * 60)
        
        start_time = datetime.now()
        
        # æŒ‰ä¾èµ–é¡ºåºåŒæ­¥
        db_count = self.sync_databases()
        table_count = self.sync_tables()
        ds_count = self.sync_datasources()
        wb_count = self.sync_workbooks()
        field_count = self.sync_fields()
        calc_count = self.sync_calculated_fields()
        
        duration = (datetime.now() - start_time).total_seconds()
        
        print("\n" + "=" * 60)
        print("ğŸ“ˆ åŒæ­¥å®Œæˆç»Ÿè®¡")
        print("=" * 60)
        print(f"  æ•°æ®åº“: {db_count}")
        print(f"  æ•°æ®è¡¨: {table_count}")
        print(f"  æ•°æ®æº: {ds_count}")
        print(f"  å·¥ä½œç°¿: {wb_count}")
        print(f"  å­—æ®µ:   {field_count}")
        print(f"  è®¡ç®—å­—æ®µ: {calc_count}")
        print(f"  è€—æ—¶: {duration:.2f} ç§’")
        print("=" * 60)
    
    def close(self):
        """å…³é—­ä¼šè¯"""
        self.session.close()


def main():
    """ä¸»å‡½æ•° - æ‰§è¡ŒåŒæ­¥"""
    print("\n" + "=" * 60)
    print("Tableau Metadata åŒæ­¥å·¥å…·")
    print("=" * 60)
    
    # é…ç½®
    BASE_URL = "http://tbi.juneyaoair.com"
    USERNAME = "huangguanru"
    PASSWORD = "Admin123"
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    client = TableauMetadataClient(BASE_URL, USERNAME, PASSWORD)
    
    # ç™»å½•
    if not client.sign_in():
        print("æ— æ³•ç™»å½•ï¼Œé€€å‡º")
        return
    
    try:
        # åˆ›å»ºåŒæ­¥ç®¡ç†å™¨
        sync = MetadataSync(client)
        
        # æ‰§è¡Œå…¨é‡åŒæ­¥
        sync.sync_all()
        
        sync.close()
        
    finally:
        # ç™»å‡º
        client.sign_out()


if __name__ == "__main__":
    main()
